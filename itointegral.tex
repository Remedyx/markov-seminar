\documentclass[11pt,a4paper, final]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage[UKenglish]{isodate}
\usepackage{epigraph}
\usepackage{url}

\newtheorem{lem}{Lemma}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{cor}{Corollary}[thm]
\newtheorem{defn}{Definition}[section]
\newtheorem{exmp}{Example}[section]
\newtheorem{rem}{Remark}[defn]

\renewcommand\thesection{\arabic{section}}


\begin{document}
\begin{titlepage} % Suppresses displaying the page number on the title page and the subsequent page counts as page 1
	
	\raggedleft % Right align the title page
	
	\rule{1pt}{\textheight} % Vertical line
	\hspace{0.05\textwidth} % Whitespace between the vertical line and title page text
	\parbox[b]{0.75\textwidth}{ % Paragraph box for holding the title page text, adjust the width to move the title page left or right on the page
		
		{\Huge\bfseries Stochastic Integration}\\[2\baselineskip] % Title
		{\large\textit{The Itô integral and Itô's formula}}\\[4\baselineskip] % Subtitle or further description
		{\Large\textsc{Remedyx \\
		Lamalini}} % Author name, lower case for consistent small caps
		
		\vspace{0.5\textheight} % Whitespace between the title block and the publisher
		
		{\noindent University of Zurich, \today }\\[\baselineskip] % Publisher and logo
	}

\end{titlepage}

\newpage
\thispagestyle{empty}
\vspace*{\fill} 
\begin{quote} 
 
\textit{ \Large In precisely built mathematical structures, mathematicians find the same sort of beauty others find in enchanting pieces of music, or in magnificent architecture. There is, however, one great difference between the beauty of mathematical structures and that of great art. Music by Mozart, for instance, impresses greatly even those who do not know musical theory; the cathedral in Cologne overwhelms spectators even if they know nothing about Christianity. The beauty in mathematical structures, however, cannot be appreciated without understanding of a group of numerical formulae that express laws of logic. Only mathematicians can read "musical scores" containing many numerical formulae, and play that "music" in their hearts.}
\end{quote}
\hfill Kiyosi Itô \textit{(1915-2008)}
\vspace*{\fill}



\newpage
\thispagestyle{empty}
\tableofcontents
\newpage
\section{Historic Background}

%Source:
% http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Ito.html

% Gauss Award
%http://www.kyoto-u.ac.jp/en/about/profile/honor/awards/gauss.html 

\epigraph{\textit{People all over realized that what Itô had done explained things that were unexplainable before.}}{Prof. Daniel Strook, MIT}

\noindent Kiyosi Itô, born 7\textit{th} of September 1915, deceased 10\textit{th} of November 2008, was a japanese mathematician. He was a pioneer in the theory of stochastic integration and stochastic differential equations. His work was so influential that it is now adays known as Itô calculus, a very important aspect of stochastic calculus. 
\\\\
At its heart, the most basic concept of Itô calculus is Itô's integral and among the most important results is a version of the fundamental theorem of calculus, known as Itô's formula.
\\\\
In 2006 Kiyosi Itô was awarded the \textit{Carl Friedrich Gauss Price}, being its first laureate, a price given to honor mathematicians for outstanding mathematical contributions that have found significant applications outside of the field of mathematics. The Gauss price is considered to be the highest honor conferred for applications of mathematics.
\\
\\
The selection of Kiyosi Itô for the first laureate reflects his achievements in the field of stochastic analysis, starting with his invention of the stochastic differential equations, which have had a significant impact on applications outside of mathematics, most notably on mathematical finance and economics \cite{KyotoUni}.
\\\\
%Source for this paragraph https://en.wikipedia.org/wiki/Order_of_Culture#2006
% and http://www-history.mcs.st-andrews.ac.uk/Obits2/Ito_Times.html
One week before his death he was awarded the Culture Medal of Japan, also known as the Order of culture, it is Japan's highest prize awarded by the Emperor himself. The Japanese mathematical community was intensely proud of him. Largely through his influence and prestige, probability theory is still strongly cultivated in Japan. Japanese probabilists tended to refer to him among themselves as \textit{"the Emperor"} \cite{Turnbull}, \cite{Emperor}, \cite{MacTutor}. 
\newpage 
\section{Abstract}
It is our goal to give a short but concise introduction to Itô's theory concerning stochastic integration. In general it is our goal to show applications of the most important results and provide a suitable amount of motivation from mathematical finance and/or economics. 
\\\\
Quite generally speaking, we will often sketch proofs by reducing them to their most important steps and leave the more technical involved steps open. The interested reader may fill in the missing gaps by consulting  Chapter 5 of \textit{T.M. Liggett's Continuous Time Markov Processes: An Introduction} \cite{Liggett}, which we used as a framework for this text. 
\\\\
We will introduce the notion of Itô's integral, first for predictable step functions and later on expand this result to obtain a general Itô integral. Moreover we will introduce Itô's formula for single martingales and for several semimartingales.
\\\\
\noindent These results are quite profound and can unequivocally be considered as revolutionizing, or to say it in the words of Revuz and Yor in their exemplary book on Brownian Motion: \textit{"To some extent, the whole sequel of this book is but an unending series of applications of Itô's formula"} \cite[page ~140]{RevuzYor}.
\\\\
A key result that we shall establish is Lévy's characterization of a Brownian Motion. The last section contains applications of Itô's formula in Finance. 
\subsection{Motivation}
\noindent Many models in the fields of economics, engineering and mathematical finance can be expressed through stochastic differential equations. Informally this can be stated as
$$ \quad dZ(t) = f(t, Z(t))dt + g(t,Z(t)) dM(t), $$
where $Z(t)$ is for example the process of interest, as the value of a certain portfolio, whereas the second term represents its variability, here $M(t)$ denotes a continuous martingale. In section 3.3 we give some concrete motivating examples. \\
\\
In order to make sense of the above expression, we need to define integrals of the form
\begin{align*} \int_0^t Y(s,\omega) \; dM(s) \tag{$\star$} 
\end{align*}
where $M(t)$ is a martingale. It turns out that a Brownian motion is the most natural choice as an integrator for our integral above. 
% source:
% https://quant.stackexchange.com/questions/17665/stochastic-differentials-itos-formula-for-a-self-financing-portfolio
\newpage 


\section{The Itô Integral}
Before we introduce the notion of Itô's integral we start with some preliminaries.
\begin{defn}
A real-valued function $f: [a,b] \rightarrow \mathbb{R}$ is said to be of \textit{bounded variation} if its total variation is finite.\\
\\ This means that 
$$ \sup_{P \in \mathcal{P}} \sum \limits_{i=1}^n \mid f(x_{i+1})-f(x_i)\mid < \infty $$
where the supremum is taken over all partitions of $[a,b]$, i.e. over the set \\  $\mathcal{P}= \lbrace P = \lbrace x_1 , \dots , x_n \rbrace \mid P \text{ is a partition of $[a,b]$ with $x_i \leq x_{i+1}$} \rbrace$
\end{defn}
\begin{rem} \label{boundedvarincreasing} It can be shown that $f: [a,b] \to \mathbb{R}$ is of bounded variation if and only if it can be written as the difference $f=f_1-f_2$ of two non-decreasing functions on $[a,b]$.
\end{rem}
\noindent As discussed in our motivating section, we strive to make sense out of integrals of the form 
\begin{align*}
\int_0^t Y(s, \omega) dM(s) \tag{$\star$} 
\end{align*} by choosing a martingale $M(t)$ as an integrator. If $M(t)$ were of bounded variation on finite $t$ intervals, we could define this just as the Stieltjes integral. As before-mentioned we do in particular want to be able to choose a Brownian motion as an integrator. 
\\\\
However, as we have seen in class, the paths of a Brownian motion are nowhere differential, henceforth they cannot be of bounded variation. \\
\\
In fact, the following result shows that there is a general problem which arises when we choose continuous paths martingales that are of bounded variation on finite $t$ intervals.
\begin{prop}  \label{first Prop}
If $M(t)$ is a martingale with continuous paths that are of bounded variation on finite $t$ intervals, then $M(t) = M(0)$ for each $t \in \mathbb{R}$ almost surely.
\end{prop}
\noindent The deeper meaning of the Proposition above is that we cannot just commit to the theory of Stieltjes integrals when we want to investigate integrals of the form $(\star)$ above. It is necessary for us to develop another theory, one for which bounded variation is not necessary. 
\\\\
In the first part of this exposition we will do just that, i.e. show the construction of the Itô integral for which we can study integrals of the form $(\star)$. 
\newpage 
\subsection{Construction of Itô's integral}
Throughout this chapter, we will assume for simplicity that $M(t)$ is a continuous martingale with respect to the right continuous filtration $\lbrace \mathcal{F}_t \rbrace$, moreover we request that $M(t)$ is square integrable, i.e. $\mathbb{E}(M^2(t)) < \infty$ for all $t \in \mathbb{R}$. By $B(t)$ we will always denote a standard Brownian motion - it will start at the origin, have mean zero and be of variance $t$ at time $t \in \mathbb{R}_+$. 
\\\\
 Finally it is worth mentioning that, in order to simplify the exposition, assumptions in the main results will often be stronger than necessary. 
\\
\\ 
Let us recall that the standard Brownian motion $B(t)$ satisfies that $B^2(t)-t$ is again a martingale. 
Our aim in this section is to extend this statement to martingales $M(t)$ by introducing the so called \textit{quadratic variation of $M(t)$} or the \textit{variance process}, denoted by $A(t)$.
\begin{thm}[Existence of the variance process] \label{variancethm}
There exists a unique increasing, continuous process, called the variance process $A(t)$ such that $A(0)=0$ and $M^2(t)-A(t)$ is a martingale.
\end{thm}
\begin{rem} \label{varianceprocessofBM}  \
\begin{enumerate} 
\item Since the variance process is increasing, Remark \ref{boundedvarincreasing} establishes that it is in particular of bounded variation. 
\item If $M(t)=B(t)$ is a Brownian motion, then of course the increasing process is just $A(t)=t$ since we already know that $B^2(t)-t$ is a martingale.
\end{enumerate} 
\end{rem}
\begin{proof}
\textsc{Uniqueness:} Suppose that $A_1(t)$ and $A_2(t)$ both satisfy the conditions of the theorem, then $A_1(t)-A_2(t)$ satisfies the assumptions of Proposition \ref{first Prop}, so $A_1(t)-A_2(t)=A_1(0)-A_2(0)=0$. And therefore $A_1(t)=A_2(t) \;$ for all $t \in \mathbb{R}$. 
\\\\
%localization nicht ganz klar ;(
\textsc{Existence:} In this part we will use the "localization" technique, which allows us to reduce it to the uniformly bounded case. Moreover we will assume that the statement has been proved for uniformly bounded martingales $M(t)$. %Macht nicht so viel Sinn?
\\\\
Given an arbitrary martingale $M(t)$, we define
$$\tau_n := n \wedge \inf\{t \geq 0: |M(t)|\geq n\}, \text{ where } n \in \mathbb{N}.$$
This sequence of stopping times increases to infinity. Furthermore we already know, that $M_n(t)=M(t \wedge \tau_n)$ is a martingale for each $n \in \mathbb{N}$. Note that by the definition of the stopping times it is bounded by $n$, i.e. $| M_n(t) |\leq n$ for all $t \in \mathbb{R}_0^+$. 
\newpage  
\noindent Using our assumption, that the theorem is true for uniformly bounded martingales, we know that there exists the variance process $A_n(t)$ of $M_n(t)$ with $A_n(0)=0$ such that $M_n^2(t)-A_n(t)$ is a martingale. We also have for $m<n$ that $M_n^2(t \wedge \tau_m)-A_n(t \wedge \tau_m)$ is a martingale. Since $M_n(t \wedge \tau_m)=M_m(t)$, the uniqueness statement implies that 
$$A_n(t \wedge \tau_m)=A_m(t) \quad i.e.\quad  A_n(t)=A_m(t) \quad for \;t\leq \tau_m.$$
So we may define the process $A(t)$ by $A(t)=A_n(t)$ for $t<\tau_n$. Also note that $A_n(t) \uparrow A(t)$ and $A_n(t)$ is constant for $t\geq \tau_n$, since we have the following
$$\mathbb{E}[A_n(t)-A_n(\tau_n), t>\tau_n]= \mathbb{E}[M_n^2(t)-M_n^2(\tau_n), t>\tau_n]=0.$$
Moreover, by Jensen's inequality we obtain that
$$M_n^2(t)=M^2(t \wedge \tau_n) \leq \mathbb{E}[M^2(t) \mid \mathcal{F}_{t \wedge \tau_n}],$$
which entails that $(M_n^2(t))_{n\geq 1}$ is uniformly integrable for each $t \in \mathbb{R}$ and we can pass to the limit in the martingale property,
$$\mathbb{E}[M_n^2(t)-A_n(t) \mid \mathcal{F}_s]=M_n^2(s)-A_n(s), \quad \text{ for all }s<t,$$
to conclude that $M^2(t)-A(t)$ is indeed is a martingale
\end{proof}
\noindent In order to construct Itô's integral we will proceed by defining it for so called predictable step functions. For the time being, we will consistently use $A(t)$ to denote the variance process corresponding to the martingale $M(t)$. 
\begin{defn} \label{defitopredictable} A predictable step function is a stochastic process of the following type
\begin{align*}
Y(t, \omega) = Y_0 ( \omega)1_{\{0\}} (t) + \sum_{i=1}^\infty Y_i( \omega) 1_{(t_i,t_{i+1}]}(t),
\end{align*}
with times $0=t_1 < t_2 < \dots $ such that $t_k \uparrow \infty$ as $k \to \infty$, $Y_i \in \mathcal{F}_{t_i}$ and $|Y_i( \omega)| \leq K$ for all $i \in \mathbb{N}$ for some constant $K$. 
For such a predictable step function, the Itô integral is defined to be 
\begin{align*}
\int_0^t Y(s) dM(s) = \sum_{i=1}^\infty Y_i  (M(t \wedge t_{i+1}) - M(t \wedge t_i)).
\end{align*}
\end{defn}
\noindent We notice that the above sum is finite, indeed since the $Y_i$ are uniformly bounded over all $i \in \mathbb{N}$, the dominating sum is telescopic and since $t_k \uparrow \infty$ for $k \to \infty$ we obtain a finite sum.
\\
\\
The following Theorem will be a cornerstone when it comes to extend the Itô integral to more general integrands, moreover it states that our definition above of the Itô integral always yields a martingale.
\newpage
\begin{thm} \label{thminequalty} Let $Y(t)$ be a preditable step function, then
\begin{align*}
M^*(t) = \int_0^t Y(s) dM(s)
\end{align*}
is a continuous, square integrable martingale. The variance process corresponding to $M^*(t)$ is given by
\begin{align*}
A^*(t) = \int_0^t Y^2(s) dA(s).
\end{align*}
Moreover we have
\begin{align*}
\mathbb{E}\left( \sup_{0 \leq s \leq t} (M^*(s))^2 \right) \leq 4 \mathbb{E}(A^*(t)).
\end{align*}
\end{thm}
\begin{proof}
The continuity and square integrability statements, as well as the fact that $M^*(t)$ is adapted, are all immediate consequences from the very definition of Itô's integral given in Definition \ref{defitopredictable}.
\\\\
For the martingale property, take $s < t$ arbitrary and notice that for all $i \in \mathbb{N}$ the expression
\begin{align*}
M(t \wedge t_{i+1}) - M(t \wedge t_i) - M (s \wedge t_{i+1}) + M( s \wedge t_i)
\end{align*}
can be written in the form of obvious martingales by considering all the cases for $s,t$. 
\\\\
To prove the second statement, notice that $A^*(t)$ is increasing and continuous, thus by Theorem \ref{variancethm} it is enough to check that $(M^*(t))^2 - A^*(t)$ is a martingale. 
\\\\
Once these two statements have been established, we notice that $M^*(0)=0$ and since $(M^*(t))^2-A(t)$ is again a martingale, we arrive at Corollary \ref{corisometry} stated seperately below due to its importance. The final statement is then just a consequence of Doob's inequality \cite[Theorem A.42 \& Remark after 5.10 p.~198]{Liggett}, since $ \mathbb{E}([M^*(t)]^2) = \mathbb{E}(A^*(t))$. 
\end{proof}
\begin{cor} \label{corisometry} \begin{align*}
\mathbb{E} \left( \left[ \int_0^t Y(s) dM(s) \right]^2\right) = \mathbb{E} \left( \int_0^t Y^2(s) dA(s) \right).
\end{align*}
\end{cor}
\noindent This isometry will be crucial when we want to extend the Itô integral to more general integrands. We will do this next.
\newpage
\begin{defn} Let $\mathcal{H}$ denote the space of all adapted stochastic processes $Y(t)$ with left continuous paths and for which we have
\begin{align*}
\mathbb{E} \left( \int_0^T Y^2(t) dA(t) \right) < \infty, \text{ for all } T >0.
\end{align*}
Then $( \mathcal{H}, \| \cdot \|_T )$ has the structure of a normed space where the norm $\| \cdot \|_T$ on $\mathcal{H}$ is given by 
\begin{align*}
\| Y\|_T^2 := \mathbb{E} \left( \int_0^T Y^2(t) dA(t) \right), \text{ for all } T >0.
\end{align*}
\end{defn}
\begin{rem} \ \begin{enumerate}
\item Naturally we say for a sequence $(Y_n)_{n \in \mathbb{N}}$ in $\mathcal{H}$ and $Y \in \mathcal{H}$ that $Y_n$ converges to $Y$ in $\mathcal{H}$ (and denote this by $Y_n \to_\mathcal{H} Y$) if $\| Y_n - Y \|_T \to 0$ as $n \to \infty$ for all $T >0$. 
\item All predictable step functions $Y$ are in $\mathcal{H}$.
\end{enumerate}
\end{rem}
\noindent By the above remark we know that the set of predictable step functions is a subset of the normed space $\mathcal{H}$, in fact, much more is true as the following Proposition entails.
\begin{prop}
The class of predictable step functions is dense in $\mathcal{H}$.
\end{prop}
\noindent The above Proposition states that our definition of predictable step functions are in a way the building blocks to more general integrands, i.e. elements in $\mathcal{H}$, in the sense that every element in $\mathcal{H}$ can be approximated by a sequence $(Y_n)_{n \in \mathbb{N}}$ of predictable step functions.  Unsurprisingly this brings us in a position to define the Itô integral for general integrands in $\mathcal{H}$. 
\begin{thm}[Itô's integral for general integrands in $\mathcal{H}$] Itô's integral for predictable step functions as defined in Definition \ref{defitopredictable} extends uniquely to $Y \in \mathcal{H}$ in such a way that it is a continuous, square integrable martingale, moreover it satisfies 
\begin{align*}
\int_0^t Y_n(s) dM(s) \to \int_0^t Y(s) dM(s) \text{ as } n \to \infty
\end{align*}
in probability, uniformly on bounded $t$ sets, whenever we have $Y_n \to_\mathcal{H} Y$ for $Y_n$ predictable step functions. Furthermore, it's quadratic variation process is given by 
\begin{align*}
\int_0^t Y^2(s) dA(s),
\end{align*}
thus 
\begin{align*}
\mathbb{E} \left( \left[ \int_0^t Y(s) dM(s) \right]^2 \right) = \mathbb{E} \left( \int_0^t Y^2(s) dA(s) \right). 
\end{align*}
\end{thm}
\newpage
\begin{proof}
By the density of the class of predictable step functions in $\mathcal{H}$ we can  for given $Y \in \mathcal{H}$ choose a sequence $(Y_n)_{n \in \mathbb{N}}$ of predictable step functions such that $Y_n \to_\mathcal{H} Y$. Since convergent sequences (with respect to the norm $\| \cdot \|_T$) are always Cauchy we obtain by linearty and the inequality stated in Theorem \ref{thminequalty} that
\begin{align*}
\mathbb{E} \left( \sup_{0 \leq t \leq T} \left[ \int_0^t Y_n(s) dM(s) - \int_0^t Y_m(s) dM(s) \right]^2 \right) \leq 4 \| Y_n -Y_m \|_T^2 \to 0 
\end{align*}
as $m,n \to \infty$. By passing to a subsequence $Y_{n_k}$ of $Y_n$ and using the Borel-Cantelli lemma, it follows that \begin{align*}
\int_0^t Y_{n_k} (s) dM(s) \to \int_0^t Y(s) dM(s) \text{ almost surely}
\end{align*}
and uniformly on bounded $t$ sets. Moreover, the uniformity of the convergence yields that the limit has continuous paths. 
\\\\
These lines of reasoning have also shown that the limit is independent of the choice of the approximating sequence $(Y_n)_{n \in \mathbb{N}}$ we have made at the beginning of the proof. 
\\\\
To check that the limit above is also a square integrable martingale and that 
\begin{align*}
\left( \int_0^t Y(s) dM(s) \right)^2 - \int_0^t Y^2(s) dA(s)
\end{align*}
is also a martingale it is enough to notice that the convergence $Y_n \to_\mathcal{H} Y$ implies both
\begin{align*}
\int_0^t Y_n(s) dM(s) \to \int_0^t Y(s) dM(s) \text{ and } \int_0^t Y_n^2(s)dA(s) \to \int_0^t Y^2(s) dA(s)
\end{align*}
in $L^2$ and $L^1$ respectively, because of the isometry shown in Corollarly \ref{corisometry}. This permits passage to the limit in the conditional expectations relevant to verify the martingale property in the two cases. 
\end{proof}
\newpage
\subsection{Itô's formula and applications}
\epigraph{\textit{To some extent, the whole sequal of this book is but an unending series of applications of Itô's formula.}}{Revuz and Yor, page 140/560}
\noindent Itô's formula is a central identity used in stochastic computations and a version of the fundamental theorem of calculus having an extra term involving the second derivative. 

\begin{thm}[Itô's formula] \label{itosformula}
Let $f: \mathbb{R} \to \mathbb{R}$ be a $C^2$-function satisfying
\begin{align*}
\mathbb{E}\left( \int_0^t [f'(M(s))]^2 dA(s) \right) < \infty \text{ and } 
\mathbb{E}\left( \int_0^t \mid f"(M(s))\mid dA(s) \right) < \infty.
\end{align*}
Then we have the identity
\begin{align*}
f(M(t))-f(M(0))= \int_0^t f'(M(s)) dM(s) + \frac{1}{2} \int_0^t f"(M(s)) dA(s). \quad (\star)
\end{align*}
\end{thm}
\noindent For the proof of this Theorem we need to extend the concept of the variance process to the one of \textit{covariance processes} associated with \textit{two} martingales:
\begin{thm}[Existence of the covariance process]
Given two square integrable continuous martingales $M_1(t)$ and $M_2(t)$, there exists a unique continuous process, called the covariance process and denoted by
$\langle M_1,M_2\rangle_t$, of bounded variation on bounded intervals, such that $\langle M_1,M_2\rangle_0=0$ and 
\begin{align*}M_1(t) M_2(t)-\langle M_1(t),M_2(t) \rangle_t \quad \text{is a martingale.}
\end{align*}
\end{thm}

\begin{proof}
The uniqueness can be proven as in the proof of the Theorem \ref{variancethm} for the variance processe, and the existence can be shown by polarization.
%Polarization is not clear at all, we need to somehow establish that this is an inner product. 
\end{proof}
\noindent We are now in a position to present a sketch of the proof of Theorem \ref{itosformula}.
\begin{proof}
By localization, it is enough to prove the result for uniformly bounded martingales satisfying $\lvert M(s) \rvert \leq K$ and $\langle M,M\rangle_s\leq K$ for all $0\leq s \leq t$ and some constant $K$.\\
\\
The equation $(\star)$ follows immediately in the case that $f(x)=x$, by just applying Definition \ref{defitopredictable}.
Using induction on $k \in \mathbb{N}$ one can show that it also holds for $f(x)=x^k$ and is therefore true for any $f$ being polynomial.
The idea in the inductive step is to assume that the statement holds for $f(x)=x^k$ and showing that it is also true for $g(x)=x f(x)$ using the integration by parts formula stated in the next paragraph.
% Das chömmer so leider nöd stoh lah :(
\\\\
 %MARCO!!! Wie chanmer das schöner darstelle? :(
For $M_1(t), \ M_2(t)$ bounded and continuous martingales, one can prove the integration by parts formula, i.e. show the identity:
\begin{align*}
M_1(t) M_2(t)=M_1(0) M_2(0) + \int_0^t M_1(s) dM_2(s) + \int_0^t M_2(s) dM_1(s) + \langle M_1,M_2\rangle_t
\end{align*}
\noindent Setting now $M_1(t)=M(t)$ and $M_2(t)= \int_0^t f'(M(s)) dM(s)$ one can conclude the result for $f$ being polynomial.\\
\\
For the general case one chooses a sequence of polynomials $f_n$ such that $f_n$ and its two first derivatives converge to $f$ and its first two derivatives are uniformly bounded on $[-K,K]$. %??? uniformly bounded? typo in script?
To pass to the limit one can now use the last statement of Theorem \ref{thminequalty}.
\end{proof}
\noindent For the rest of this illustration we would like to focus on applications of Itô's formula. The following Lemma is an immediate, but nevertheless interesting consequence.
\begin{lem} Let $B(t)$ denote a standard Brownian Motion, then 
\begin{align*}
\int_0^t B(s) dB(s) = \frac{1}{2}( B^2(t)-t).
\end{align*}
\end{lem}
\begin{proof}
Let us consider $f: \mathbb{R} \to \mathbb{R}$, given by $f(x) = x^2/2$, then we have $f \in C^2( \mathbb{R})$ and $f'(x)=x, \ f''(x) = 1$. We check the conditions of Itô's formula, recall that by Remark \ref{varianceprocessofBM} we have that the quadratic variance process associated to a Brownian Motion $B(t)$ is just given by $A(t)=t$, as a consequence we simply have $dA(s)=ds$. 
\begin{align*}
\mathbb{E} \left( \int_0^t B^2(s) dA(s) \right) &= \mathbb{E} \left( \int_0^t B^2(s) ds \right) = \int_0^t \mathbb{E}(B^2(s) ) ds \\ &  = \int_0^t s ds = \frac{t^2}{2} < \infty.
\end{align*} 
Moreover, we have
\begin{align*}
\mathbb{E} \left( \int_0^t dA(s) \right) = \mathbb{E}\left( \int_0^t ds \right) = t < \infty. 
\end{align*}
By Itô's formula we obtain
\begin{align*}
\frac{B^2(t)}{2}- 0 = \int_0^t B(s) dB(s) + \frac{1}{2} \int_0^t ds.
\end{align*}
We conclude $\displaystyle \int_0^t B(s) dB(s) = \frac{1}{2}(B^2(t)-t)$ as claimed. 
\end{proof}
\begin{rem} Since we already know that the Itô integral defines a martingale, we rediscover from the lemma above the fact that $B^2(t)-t$ is a martingale. 
\end{rem}
\newpage
\noindent For many applications, it is important to have a more general form of Itô's formula, in order to arrive at this result the notion of semimartingales is important. The next definition permits the formulation of results for stochastic integrals and Stieltjes integrals in a unified way. 
\begin{defn} \label{defsemimartingale} A continuous semimartingale is a stochastic process $X(t)$ that can be written in the form $X(t)=M(t) + D(t)$, where $M(t)$ is a continuous martingale and $D(t)$ is a continuous adapted process of bounded variation on bounded $t$ sets satisfying $D(0)=0$. 
\\\\
For a sequence of continuous semimartingales $X_i(t)= M_i(t) + D_i(t)$, where $i \in \mathbb{N}$, the covariance process is defined by $\langle X_i, X_j \rangle_t = \langle M_i, M_j \rangle_t$ for all $i,j \in \mathbb{N}$. 
\\\\
Finally, Integrals are defined by 
\begin{align*}
\int_0^t Y(s) dX(s) = \int_0^t Y(s) dM(s) + \int_0^t Y(s) dD(s),
\end{align*}
whenever the integrals on the right hand side are well-defined. The first integral is the Itô integral, whereas the second integral is a Stieltjes integral. 
\end{defn}
\begin{rem}  \ 
\begin{enumerate} 
\item Every continuous Martingale $M(t)$ is also a continuous semimartingale. 
\item The decomposition of the stochastic process $X(t)=M(t) + D(t)$ is unique thanks to Proposition \ref{first Prop}. 
\end{enumerate} 
\end{rem}
\noindent Itô's formula (Theorem \ref{itosformula}) extends naturally to a vector of semimartingales. Its proof works analogeously to the one presented in Theorem \ref{itosformula} and will be ommited here.
\begin{thm}[Generalization of Itô's formula] Let $X(t) = (X_1(t), \dots , X_n(t))$, where $X_i(t)$ are continuous semimartingales for all $i=1, \dots ,n$ be a vector of continuous semimartingales. Let $f: \mathbb{R}^n \to \mathbb{R}$ be a function of class $C^2$ and suppose that all integrals appearing in the formula below are well-defined, then 
\begin{align*}
f(X(t))-f(X(0)) = & \sum_{i=1}^n \int_0^t \dfrac{\partial f}{\partial x_i} (X(s)) dX_i(s)
\\ & + \frac{1}{2} \sum_{i,j=1}^n \int_0^t \dfrac{\partial^2 f	}{\partial x_i \partial x_j}(X(s))d \langle X_i, X_j \rangle_s. 
\end{align*}
\end{thm}
\noindent As an application of the generalized Itô's formula we will provide a method to generate many new martingales from a given one. 
\newpage
\begin{thm} \label{fromitotomartingale} Suppose $f: \mathbb{R}^2 \to \mathbb{R}$ or $\mathbb{C}$ is a $C^2$-function and satisfies \begin{align*}
\dfrac{\partial f}{\partial y} + \frac{1}{2} \dfrac{\partial^2 f}{\partial x^2}= 0. 
\end{align*}
Let $M(t)$ be a continuous square integrable martingale and define the random vector $X(t):=(M(t), \langle M, M \rangle_t )$. If for every $t \in \mathbb{R}_+$ 
\begin{align*}
\mathbb{E} \left( \int_0^t \left[ \left| \dfrac{\partial f}{\partial x}(X(s)) \right|^2 + \left| \dfrac{\partial f}{\partial y} (X(s)) \right| \right] d \langle M, M \rangle_s \right) < \infty \tag{$\diamondsuit$}
\end{align*}
then $f(X(t))$ is a martingale. 
\end{thm}
\begin{proof} It is enough to consider a real-valued $f$, of course the result can be generalized to $\mathbb{C}$ by applying the statement separately to the real and the imaginary part of $f$. 
\\\\
We have $n=2$ and $X(t)=(M(t), \langle M, M \rangle_t)$, i.e. $X_1(t)=  M(t)$ and $X_2(t)= \langle M, M \rangle_t$ which are indeed both continuous semimartingales, in particular we have for $X_2$ the unique decomposition (see Definition \ref{defsemimartingale}) $X_2(t)=0 + \langle M, M \rangle_t$ because $\langle M, M \rangle_t$ is (locally) of bounded variation. This entails that $\langle X_1, X_2 \rangle_t = \langle M(t), 0 \rangle_t=0= \langle X_2, X_1 \rangle_t = \langle X_2, X_2 \rangle_t$.  
\\\\
Therefore the sum on Itô's formula breaks down to the three terms below
\begin{align*}
f(X(t))-f(X(0)) = &\int_0^t \dfrac{\partial f}{\partial x}(X(s))dM(s) + \int_0^t \dfrac{\partial f}{\partial y}(X(s)) d \langle M, M \rangle_s  \\
& +\frac{1}{2} \int_0^t \dfrac{\partial^2f}{\partial x^2}(X(s)) d \langle M, M \rangle_s.
\end{align*}
They are all well defined because of the condition $(\diamondsuit)$, moreover the 2 right most terms vanish because by assumption we have that 
\begin{align*}
\dfrac{\partial f}{\partial y}+ \frac{1}{2} \frac{\partial^2 f}{\partial x^2} =0.
\end{align*}
Henceforth we are left with
\begin{align*}
f(X(t))-f(X(0)) = \int_0^t \dfrac{\partial f}{\partial x} (X(s)) dM(s),
\end{align*}
which is a martingale. 
\end{proof}
\noindent Before we come to applications of Itô's formula in the theme of mathematical finance we present a very interesting application of the above theorem, it gives us a characterization of a standard Brownian Motion. 
\\\\
We recall that one way to characterize a standard Brownian Motion is to say that it is a continuous stochastic process $(B_t)_{t \geq 0}$ starting at $0$ with stationary, independent increments and $B_t \sim \mathcal{N}(0,t)$ for all $t \geq 0$. 
\newpage
\begin{thm}[Lévy's characterization of a standard Brownian Motion] Let $M(t)$ be a continuous, square integrable martingale. $M(t)$ is a standard Brownian Motion if and only if $M(0)=0$ and $\langle M,M \rangle_t = t$.
\end{thm}
\begin{proof}
Indeed if $M(t)=B(t)$ is a standard Brownian Motion, then we already know that it is a continuous, square integrable martingale with $B(0)=0$ and we also established, in Remark \ref{varianceprocessofBM}, that its variance process $\langle M, M \rangle_t$ is given by $t$.
\\\\
Conversely, let us suppose that $M(t)$ is a continuous, square integrable martingtale that satisfies $M(0)=0$ and its variance process is given by $\langle M, M \rangle_t =t$.  Let us consider for a fixed $u \in \mathbb{R}$ the complex valued function $f: \mathbb{R}^2 \to \mathbb{C}$ given by 
\begin{align*}
f(x,y)= \exp ( iux+(u^2/2)y),
\end{align*}
then indeed $f$ is of class $C^2$ and it satisfies 
\begin{align*}
\dfrac{\partial f}{\partial y} + \frac{1}{2} \dfrac{\partial^2f}{\partial x^2}=0.
\end{align*}
Moreover, we have $X(t)=(M(t), \langle M, M \rangle_t ) = (M(t), t)$. We easily verify that the condition $(\diamondsuit)$ in Theorem \ref{fromitotomartingale} holds, in order to see this just make use of the fact that 
\begin{align*}
\left| \dfrac{\partial f}{\partial y}(X(s)) \right|
= \left| \frac{u^2}{2} e^{iu M(s) + (u^2/2)s} \right| \leq \frac{u^2}{2} e^{(u^2/2)s}
\end{align*} 
and similarly for the 1st partial derivative. Theorem \ref{fromitotomartingale} now yields that  
\begin{align*}
f(X(t)) = \exp \left( i u M(t) + \frac{u^2}{2}t \right) 
\end{align*}
is a Martingale. Therefore, for all $s <t$ we must have 
\begin{align*}
\mathbb{E}(f(X(t)) \mid \mathcal{F}_s) = f(X(s))
\end{align*}
or equivalently 
\begin{align*}
\mathbb{E}\left( \exp \left[ i u M(t) + \frac{u^2}{2}t \right] \mid \mathcal{F}_s \right) = \exp \left( i u M(s) + \frac{u^2}{2}s \right). 
\end{align*}
Rearranging those terms we get 
\begin{align*}
\mathbb{E} \left( e^{iu(M(t)-M(s))} \mid \mathcal{F}_s \right) = e^{- \left( \frac{u^2}{2} \right)(t-s)}.
\end{align*}
By identifying the characteristic function we conclude that $M(t)-M(s)$ is independent of $\mathcal{F}_s$ and has a Gaussian distribution with mean $0$ and variance $t-s$. This entails that $M(t)$ is a standard Brownian motion. 
\end{proof}
\newpage
\subsection{Application of Itô's formula in Finance}
In this last section we give some more concrete examples that come from the field of mathematical finance.  \\
\\
Suppose we have a portfolio of Stocks ($S$) and savings account ($\beta_t$), then the value of the portfolio is
$$ V=a_t S_t + b_t \beta_t. $$
Now let $$a_t=2 B_t;\quad b_t=-1-B_t^2-20 B_t;\quad S_t=10+B_t;\quad \beta_t=1,$$
where $B_t$ denotes a Brownian Motion at time $t$.
We now can easily show, using Itô's formula, that this portfolio is self-financing:

\begin{align*} V&=a_t S_t + b_t \beta_t = 2 B_t(10+B_t) +(-t-B_t^2-20B_t)\cdot 1\\
&=20B_t + 2B_t^2-t-B_t^2-20B_t \\
&=B_t^2-t. 
\end{align*}
Applying Itô's formula [$f(B_t) \Longrightarrow df=f'(B_t)dB_t + \frac{1}{2} f"(B_t)dt$] and quadratic variation [$(dB_t)^2=dt$] to it we get
\begin{align*}  dV_t &= (2B_t dB_t + \frac{1}{2}\cdot 2 \langle B, B \rangle_t)-dt\\
&= 2 B_t dB_t\\
&= a_t dS_t + b_t d\beta_t.
\end{align*}
Moreover, since $dS_t = dB_t$ and $d\beta_t=0$ we obtain
\begin{align*}
dV_t = a_t dS_t + b_t d\beta_t, 
\end{align*}
which is a characterization of a self-financing portfolio.
\newpage
\noindent We will look at the usual model for the time-evolution of an asset price $S(t)$.
The original paper by Black and Scholes assumes that the price of the underlying asset is a stochastic process $S(t)$ solving the following stochastic differential equation (SDE)
\begin{align*}
dS(t)=\mu S(t) dt + \sigma S(t) dB(t),
\end{align*}
where $\mu$ denotes the continuously compounded expected return on the stock (drift), $\sigma$ represents the volatility and $B(t)$ is a standard Brownian motion. For simplicity we will assume here $\mu$ and $\sigma$ to be constant. 
In other words, $S(t)$ is a \textit{geometric Brownian motion}.\\
\\
Dividing by $S(t)$ in the equation above yields
\begin{align*}\frac{dS(t)}{S(t)}=\mu dt + \sigma dB(t).\tag{ $\star$}
 \end{align*}
Notice that the left-hand side looks similar to the derivative of $\log{S(t)}$.\\
Applying the generalized Itô's formula for semimartingales to the function $f(t,x)=\log(x)\in C^2(\mathbb{R}_+^2,\mathbb{R})$ and using that $\partial_t f(t,x)=0$, we get 
%[-->plug it in in $df(t,X_t)= \partial_t f(t,X_t)dt + \partial_x f(t.X_t) dX_t + 1/2 \partial_{xx} f(t,X_t) d<X,X>_t$]
\begin{align*}
d(\log(S_t))&=\frac{1}{S_t} \, dS_t + \frac{1}{2}\cdot \left(-\frac{1}{S^2_t} \right) d\langle S,S\rangle_t 
= \frac{1}{S_t} dS_t -\frac{1}{2} \sigma^2 dt \\
&\stackrel{(\star)}{=} \mu \, dt + \sigma \, dB(t) -\frac{1}{2} \sigma^2 \, dt
=\left(\mu -\frac{1}{2} \sigma^2\right)\, dt + \sigma \, dB(t).
\end{align*}
It follows that
\begin{align*}\log(S(t))-\log(S(0)) =\left(\mu -\frac{1}{2} \sigma^2\right)t + \sigma B(t).
\end{align*}
Taking the exponential of this equation finally gives us:
\begin{align*}
S(t)=S(0) \cdot \exp\left( \left(\mu - \frac{1}{2}\sigma^2\right)\cdot t + \sigma B(t)\right).
\end{align*}
This is the solution to the SDE, and one can see that the process $S(t)$ is lognormally distributed as predicted by the Black-Scholes model.

\newpage
\section{Bibliography}
\begin{thebibliography}{9}

\bibitem{Liggett}
  Thomas M. Liggett,
  \textit{Continuous Time Markov Processes: An Introduction},
  Volume 113 of Graduate Studies in Mathematics, American Mathematical Society,
  Providence, Rhode Island,
  2010.

\bibitem{KyotoUni}
	Kyoto University
	\textit{Dr. Kiyosi Itô receives Gauss Prize}, \url{http://www.kyoto-u.ac.jp/en/about/profile/honor/awards/gauss.html}, \\ \textsc{Accessed}: 14.12.2017

\bibitem{Turnbull}
	Turnbull, School of Mathematics and Statistics, University of St. Andrews, \textit{Kiyosi Itô}, \url{http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Ito.html}, \textsc{Accessed}: 14.12.2017

\bibitem{Emperor}
	Turnbull, School of Mathematics and Statistics, University of St. Andrews, \textit{Kiyosi Itô receives Order of Culture}, \url{http://www-groups.dcs.st-and.ac.uk/~history/Obits2/Ito_Times.html}, \\ \textsc{Accessed}: 14.12.2017

\bibitem{MacTutor}
	History of Mathematics archives, University of St. Andrews, \textit{Professor Kiyosi Itô: Mathematician and probability theory expert}, \url{http://www-history.mcs.st-andrews.ac.uk/Obits2/Ito_Times.html}, \\  \textsc{Accessed} 15.12.2017

\bibitem{RevuzYor}
	Daniel Revuz and Marc Yor, \textit{Continuous Martingales and Brownian Motion}, 2nd Edition, Springer, 1994. 

\end{thebibliography}

\end{document}