\documentclass[11pt,a4paper, final]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage[UKenglish]{isodate}

\newtheorem{lem}{Lemma}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{cor}{Corollary}[thm]
\newtheorem{defn}{Definition}[section]
\newtheorem{exmp}{Example}[section]
\newtheorem{rem}{Remark}[defn]

\renewcommand\thesection{\arabic{section}}



\begin{document}
\begin{titlepage} % Suppresses displaying the page number on the title page and the subsequent page counts as page 1
	
	\raggedleft % Right align the title page
	
	\rule{1pt}{\textheight} % Vertical line
	\hspace{0.05\textwidth} % Whitespace between the vertical line and title page text
	\parbox[b]{0.75\textwidth}{ % Paragraph box for holding the title page text, adjust the width to move the title page left or right on the page
		
		{\Huge\bfseries Stochastic Integration}\\[2\baselineskip] % Title
		{\large\textit{The Itô integral and Itô's formula}}\\[4\baselineskip] % Subtitle or further description
		{\Large\textsc{Remedyx \\
		Lamalini}} % Author name, lower case for consistent small caps
		
		\vspace{0.5\textheight} % Whitespace between the title block and the publisher
		
		{\noindent University of Zurich, \today }\\[\baselineskip] % Publisher and logo
	}

\end{titlepage}
%\newpage 
%\thispagestyle{empty}
%\null\vfill
%\begin{center}
%\begin{flushleft}
%\textit{\Large In precisely built mathematical structures, mathematicians find the same sort of beauty others find in enchanting pieces of music, or in magnificent architecture. There is, however, one great difference between the beauty of mathematical structures and that of great art. Music by Mozart, for instance, impresses greatly even those who do not know musical theory; the cathedral in Cologne overwhelms spectators even if they know nothing about Christianity. The beauty in mathematical structures, however, cannot be appreciated without understanding of a group of numerical formulae that express laws of logic. Only mathematicians can read "musical scores" containing many numerical formulae, and play that "music" in their hearts. } 
%\end{flushleft}
%\end{center}
%\hfill Kiyosi Itô \textit{(1915-2008)}
%\vfill\vfill

\newpage
\thispagestyle{empty}
\vspace*{\fill} 
\begin{quote} 
 
\textit{ \Large In precisely built mathematical structures, mathematicians find the same sort of beauty others find in enchanting pieces of music, or in magnificent architecture. There is, however, one great difference between the beauty of mathematical structures and that of great art. Music by Mozart, for instance, impresses greatly even those who do not know musical theory; the cathedral in Cologne overwhelms spectators even if they know nothing about Christianity. The beauty in mathematical structures, however, cannot be appreciated without understanding of a group of numerical formulae that express laws of logic. Only mathematicians can read "musical scores" containing many numerical formulae, and play that "music" in their hearts.}
\end{quote}
\hfill Kiyosi Itô \textit{(1915-2008)}
\vspace*{\fill}



\newpage
\thispagestyle{empty}
\tableofcontents
\newpage
\section{Historic Background}

%Source:
% http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Ito.html

% Gauss Award
%http://www.kyoto-u.ac.jp/en/about/profile/honor/awards/gauss.html 


Kiyosi Itô born 7\textit{th} of September 1915, deceased 10\textit{th} of November 2008, was a japanese mathematician. He was a pioneer in the theory of stochastic integration and stochastic differential equations. His work was so influencal that it is now adays known as Itô calculus, a very important aspect of stochastic calculus. 
\\\\
At its heart, the most basic concept of Itô calculus is Itô's integral and among the most important results is a version of the fundamental theorem of calculus, known as Itô's formula.
\\\\
In 2006 Kiyosi Itô was awarded the \textit{Carl Friedrich Gauss Price}, being its first laureate, a price given to honor mathematicians for outstanding mathematical contributions that have found significant applications outside of the field of mathematics. The Gauss price is considered to be the highest honor conferred for applications of mathematics.
\\
\\
The selection of Kiyosi Itô for the first laureate reflects the achievements in the field of stochastic analysis, starting with his invention of the stochastic differential equations, which have had a significant impact on applications outside of mathematics, most notably on mathematical finance and economy. 
\section{Abstract}
It is our goal to give a short but concise introduction to Itô's theory concerning stochastic integration. In general it is our goal to show applications of the most important results and provide a suitable amount of motivation from mathematical finance and/or economy. 
\\\\
Quite generally speaking, we will often sketch proofs by reducing them to their most important steps (such as for instance localization) and leave the more technical involved steps open. The interested reader may fill in the missing gaps by consulting  Chapter 5 of \textit{T.M. Liggett's Continuous Time Markov Processes: An Introduction,} which we used as a framework for this text. 
\\\\
We will introduce the notion of Itô's integral, first for predictable step functions and later on expand this result to obtain a general Itô integral. Moreover we will introduce Itô's formula for single martingales and for several semimartingales.
\newpage  

\noindent These results are quite profound and can unequivocally be considered as revolutionizing, or to say it in the words of Revuz and Yor in their exemplary book on Brownian Motion: \textit{"To some extent, the whole sequel of this book is but an unending series of applications of Itô's formula"}.
\\\\
We will finish by giving several applications of Itô's formula. 


% source:
% https://quant.stackexchange.com/questions/17665/stochastic-differentials-itos-formula-for-a-self-financing-portfolio
\section{Application of Itô's formula in Finance}
In order to motivate the importance of Itô's formula we start by giving an example from mathematical finance. \\
\\
Suppose we have a portfolio of Stocks ($S$) and savings account ($\beta_t$), then the value of the portfolio is
$$ V=a_t S_t + b_t \beta_t $$
Now let $$a_t=2 B_t;\quad b_t=-1-B_t^2-20 B_t;\quad S_t=10+B_t;\quad \beta_t=1$$
where $B_t$ denotes a Brownian Motion at time $t$.
We now can easily show using Itô's formula, that this portfolio is self-financing:

\begin{align*} V&=a_t S_t + b_t \beta_t = 2 B_t(10+B_t) +(-t-B_t^2-20B_t)\cdot 1\\
&=20B_t + 2B_t^2-t-B_t^2-20B_t \\
&=B_t^2-t 
\end{align*}
Applying Itô's formula [$f(B_t) \Longrightarrow df=f'(B_t)dB_t + \frac{1}{2} f"(B_t)dt$] and quadratic variation [$(dB_t)^2=dt$] to it we get
\begin{align*}  dV_t &= (2B_t dB_t + \frac{1}{2}\cdot 2 \langle B, B \rangle_t)-dt\\
&= 2 B_t dB_t\\
&= a_t dS_t + b_t d\beta_t
\end{align*}
Moreover, since $dS_t = dB_t$ and $d\beta_t=0$ we obtain
\begin{align*}dV_t = a_t dS_t + b_t d\beta_t \end{align*}
which is a characterization of a self-financing portfolio.
\newpage
\noindent The preceeding example motivates a more general setting that often occurs in many models in the fields of economics, engineering and mathematical finance. Informally it can be stated as
$$ \quad dZ(t) = f(t, Z(t))dt + g(t,Z(t)) dM(t), $$
where $Z(t)$ is the process of interest, as the value of a certain portfolio in the example above.\\
\\
In order to make sense of the above expression, we need to define integrals of the form
\begin{align*} \int_0^t Y(s,\omega) \; dM(s) \tag{$\star$} 
\end{align*}
where $M(t)$ is a martingale. It turns out that the Brownian motion is the most natural choice as an integrator for our integral above. 

\newpage

\section{The Itô Integral}
Before we introduce the notion of Itô's integral we start with some preliminaries.
\begin{defn}
A real-valued function $f: [a,b] \rightarrow \mathbb{R}$ is said to be of \textit{bounded variation} if its total variation is finite.\\
\\ This means that 
$$ \sup_{P \in \mathcal{P}} \sum \limits_{i=1}^n \mid f(x_{i+1})-f(x_i)\mid < \infty $$
where the supremum is taken over all partitions of $[a,b]$, i.e. over the set \\  $\mathcal{P}= \lbrace P = \lbrace x_1 , \dots , x_n \rbrace \mid P \text{ is a partition of $[a,b]$ with $x_i \leq x_{i+1}$} \rbrace$
\end{defn}

\noindent As discussed in our motivating section, we strive to make sense out of integrals of the form 
\begin{align*}
\int_0^t Y(s, \omega) dM(s) \tag{$\star$} 
\end{align*} by choosing a martingale $M(t)$ as an integrator. If $M(t)$ were of bounded variation on finite $t$ intervals, we could define this just as the Stieltjes integral. As before-mentioned we do in particular want to be able to choose a Brownian motion as an integrator. 
\\\\
However, as we have seen in class, the paths of a Brownian motion are nowhere differential, henceforth they cannot be of bounded variation. \\
\\
In fact, the following result shows that there is a general problem which arises when we choose continuous paths martingales that are of bounded variation on finite $t$ intervals.
\begin{prop}  \label{first Prop}
If $M(t)$ is a martingale with continuous paths that are of bounded variation on finite $t$ intervals, then $M(t) = M(0)$ for each $t \in \mathbb{R}$ almost surely.
\end{prop}
\noindent The deeper meaning of the Proposition above is that we cannot just commit to the theory of Stieltjes integrals when we want to investigate integrals of the form $(\star)$ above. It is necessary for us to develop another theory, one for which bounded variation is not necessary. 
\\\\
In the first part of this exposition we will do just that, i.e. show the construction of the Itô integral for which we can study integrals of the form $(\star)$. 
\newpage 
\subsection{Construction of Itô's integral}
Throughout this chapter, we will assume for simplicity that $M(t)$ is a continuous martingale with respect to the right continuous filtration $\lbrace \mathcal{F}_t \rbrace$, moreover we request that $M(t)$ is square integrable, i.e. $\mathbb{E}(M^2(t)) < \infty$ for all $t \in \mathbb{R}$. By $B(t)$ we will always denote a standard Brownian motion - it will start at the origin and be of variance $t$ at time $t$. 
\\\\
 Finally it is worth mentioning that, in order to simplify the exposition, assumptions in the main results will often be stronger than necessary. 
\\
\\ 
Let us recall that the standard Brownian motion $B(t)$ satisfies that $B^2(t)-t$ is again a martingale. 
Our aim in this section is to extend this statement to martingales $M(t)$ by introducing the so called \textit{quadratic variation of $M(t)$} or the \textit{variance process}, denoted by $A(t)$.
\begin{thm} \label{variancethm}
There exists a unique increasing, continuous process, called the variance process $A(t)$ such that $A(0)=0$ and $M^2(t)-A(t)$ is a martingale.
\end{thm}
\begin{proof}
\textsc{Uniqueness:} Suppose that $A_1(t)$ and $A_2(t)$ both satisfy the conditions of the theorem, then $A_1(t)-A_2(t)$ satisfies the assumptions of Proposition \ref{first Prop}, so $A_1(t)-A_2(t)=A_1(0)-A_2(0)=0$. And therefore $A_1(t)=A_2(t) \;$ for all $t \in \mathbb{R}$. 
\\\\
%localization nicht ganz klar ;(
\textsc{Existence:} In this part we will use the "localization" technique, which allows us to reduce it to the uniformly bounded case. Moreover we will assume that the statement has been proved for uniformly bounded martingales $M(t)$. %Macht nicht so viel Sinn?
\\\\
Given an arbitrary martingale $M(t)$, we define
$$\tau_n := n \wedge \inf\{t \geq 0: |M(t)|\geq n\}, \text{ where } n \in \mathbb{N}.$$
This sequence of stopping times increases to infinity. Furthermore we already know, that $M_n(t)=M(t \wedge \tau_n)$ is a martingale for each $n \in \mathbb{N}$. Note that by the definition of the stopping times it is bounded by $n$, i.e. $| M_n(t) |\leq n$. Using our assumption, that the theorem is true for uniformly bounded martingales, we know that there exists the variance process $A_n(t)$ of $M_n(t)$ with $A_n(0)=0$ so that $M_n^2(t)-A_n(t)$ is a martingale. We also have for $m<n$ $$M_n^2(t \wedge \tau_m)-A_n(t \wedge \tau_m)$$ is a martingale.
\newpage

\noindent Since $M_n(t \wedge \tau_m)=M_m(t)$, the uniqueness statement implies that 
$$A_n(t \wedge \tau_m)=A_m(t) \quad i.e.\quad  A_n(t)=A_m(t) \quad for \;t\leq \tau_m.$$
So we may define the process $A(t)$ by $A(t)=A_n(t)$ for $t<\tau_n$. Also note that $A_n(t) \uparrow A(t)$ and $A_n(t)$ is constant for $t\geq \tau_n$, since we have the following
$$\mathbb{E}[A_n(t)-A_n(\tau_n), t>\tau_n]= \mathbb{E}[M_n^2(t)-M_n^2(\tau_n), t>\tau_n]=0$$
Moreover, by Jensen's inequality we obtain that
$$M_n^2(t)=M^2(t \wedge \tau_n) \leq \mathbb{E}[M^2(t) \mid \mathscr{F}_{t \wedge \tau_n}],$$
which entails that $(M_n^2(t))_{n\geq 1}$ is uniformly integrable for each $t \in \mathbb{R}$ and we can pass to the limit in the martingale property to conclude that $M^2(t)-A(t)$ is indeed is a martingale
$$\mathbb{E}[M_n^2(t)-A_n(t) \mid \mathscr{F}_s]=M_n^2(s)-A_n(s), \quad \text{ for all }s<t.$$

\end{proof}
\noindent In order to construct Itô's integral we will proceed by defining it for so called predictable step functions. For the time being, we will consistently use $A(t)$ to denote the variance process corresponding to the martingale $M(t)$. 
\begin{defn} \label{defitopredictable} A predictable step function is a stochastic process of the following type
\begin{align*}
Y(t, \omega) = Y_0 ( \omega)1_{\{0\}} (t) + \sum_{i=1}^\infty Y_i( \omega) 1_{(t_i,t_{i+1}]}(t)
\end{align*}
with times $0=t_1 < t_2 < \dots $ such that $t_k \uparrow \infty$ as $k \to \infty$, $Y_i \in \mathcal{F}_{t_i}$ and $|Y_i( \omega)| \leq K$ for all $i \in \mathbb{N}$ for some constant $K$. 
For such a predictable step function, the Itô integral is defined to be 
\begin{align*}
\int_0^t Y(s) dM(s) = \sum_{i=1}^\infty Y_i  (M(t \wedge t_{i+1}) - M(t \wedge t_i))
\end{align*}
\end{defn}
\noindent We notice that the above sum is finite, indeed since the $Y_i$ are uniformly bounded over all $i \in \mathbb{N}$, the dominating sum is telescopic and since $t_k \uparrow \infty$ for $k \to \infty$ we obtain a finite sum.
\\
\\
The following Theorem is a cornerstone when it comes to extend the Itô integral to more general integrands.
\newpage
\begin{thm} \label{thminequalty} Let $Y(t)$ be a preditable step function, then
\begin{align*}
M^*(t) = \int_0^t Y(s) dM(s)
\end{align*}
is a continuous, square integrable martingale. The variance process corresponding to $M^*(t)$ is given by
\begin{align*}
A^*(t) = \int_0^t Y^2(s) dA(s)
\end{align*}
Moreover we have
\begin{align*}
\mathbb{E}\left( \sup_{0 \leq s \leq t} (M^*(s))^2 \right) \leq 4 \mathbb{E}(A^*(t))
\end{align*}
\end{thm}
\begin{proof}
The continuity and square integrability statements, as well as the fact that $M^*(t)$ is adapted, are all immediate consequences from the very definition of Itô's integral given in Definition \ref{defitopredictable}.
\\\\
For the martingale property, take $s < t$ arbitrary and note that for all $i \in \mathbb{N}$ the expression
\begin{align*}
M(t \wedge t_{i+1}) - M(t \wedge t_i) - M (s \wedge t_{i+1}) + M( s \wedge t_i)
\end{align*}
can be written in the form of obvious martingales by considering all the cases for $s,t$. 
\\\\
To prove the second statement, notice that $A^*(t)$ is increasing and continuous, thus by Theorem \ref{variancethm} it is enough to check that $(M^*(t))^2 - A^*(t)$ is a martingale. 
\\\\
The final statement is just a consequence of Doob's inequality. 
\end{proof}
\noindent Since we have $M^*(0)=0$ and by Theorem \ref{variancethm} we know that $(M^*(t))^2 -A(t)$ is again a martingale, we easily arrive at
\begin{cor} \label{corisometry} \begin{align*}
\mathbb{E} \left( \left[ \int_0^t Y(s) dM(s) \right]^2\right) = \mathbb{E} \left( \int_0^t Y^2(s) dA(s) \right) 
\end{align*}
\end{cor}
\noindent This isometry will be crucial when we want to extend the Itô integral to more general integrands. We will do this next.
\newpage
\begin{defn} Let $\mathcal{H}$ denote the space of all adapted stochastic processes $Y(t)$ with left continuous paths and for which we have
\begin{align*}
\mathbb{E} \left( \int_0^T Y^2(t) dA(t) \right) < \infty, \text{ for all } T >0
\end{align*}
Then $( \mathcal{H}, \| \cdot \|_T )$ has the structure of a normed space where the norm $\| \cdot \|_T$ on $\mathcal{H}$ is given by 
\begin{align*}
\| Y\|_T^2 := \mathbb{E} \left( \int_0^T Y^2(t) dA(t) \right), \text{ for all } T >0 
\end{align*}
\end{defn}
\begin{rem} \ \begin{enumerate}
\item Naturally we say for a sequence $(Y_n)_{n \in \mathbb{N}}$ in $\mathcal{H}$ and $Y \in \mathcal{H}$ that $Y_n$ converges to $Y$ in $\mathcal{H}$ (and denote this by $Y_n \to_\mathcal{H} Y$) if $\| Y_n - Y \|_T \to 0$ as $n \to \infty$ for all $T >0$. 
\item All predictable step functions $Y$ are in $\mathcal{H}$.
\end{enumerate}
\end{rem}
\noindent By the above remark we know that the set of predictable space functions is a subset of the normed space $\mathcal{H}$, in fact, much more is true as the following Proposition entails.
\begin{prop}
The class of predictable step functions is dense in $\mathcal{H}$ 
\end{prop}
\noindent The above Proposition states that our definition of predictable step functions are in a way the building blocks to more general integrands, i.e. elements in $\mathcal{H}$, in the sense that every element in $\mathcal{H}$ can be approximated by a sequence $(Y_n)_{n \in \mathbb{N}}$ of predictable step functions.  Unsurprisingly this brings us in a position to define the Itô integral for general integrands in $\mathcal{H}$. 
\begin{thm}[Itô's integral for general integrands in $\mathcal{H}$] Itô's integral for predictable step functions as defined in Definition \ref{defitopredictable} extends uniquely to $Y \in \mathcal{H}$ in such a way that it is a continuous, square integrable martingale, moreover it satisfies 
\begin{align*}
\int_0^t Y_n(s) dM(s) \to \int_0^t Y(s) dM(s) \text{ as } n \to \infty
\end{align*}
in probability, uniformly on bounded $t$ sets, whenever we have $Y_n \to_\mathcal{H} Y$ for $Y_n$ predictable step functions. Furthermore, it's quadratic variation process is given by 
\begin{align*}
\int_0^t Y^2(s) dA(s)
\end{align*}
thus 
\begin{align*}
\mathbb{E} \left( \left[ \int_0^t Y(s) dM(s) \right]^2 \right) = \mathbb{E} \left( \int_0^t Y^2(s) dA(s) \right) 
\end{align*}
\end{thm}
\newpage
\begin{proof}
By the density of the class of predictable step functions in $\mathcal{H}$ we can  for given $Y \in \mathcal{H}$ choose a sequence $(Y_n)_{n \in \mathbb{N}}$ of predictable step functions such that $Y_n \to_\mathcal{H} Y$. Since convergent sequences (with respect to the norm $\| \cdot \|_T$) are always Cauchy we obtain by linearty and inequality stated in Theorem \ref{thminequalty} that
\begin{align*}
\mathbb{E} \left( \sup_{0 \leq t \leq T} \left[ \int_0^t Y_n(s) dM(s) - \int_0^t Y_m(s) dM(s) \right]^2 \right) \leq 4 \| Y_n -Y_m \|_T^2 \to 0 
\end{align*}
as $m,n \to \infty$. By passing to a subsequence $Y_{n_k}$ of $Y_n$ and using the Borel-Cantelli lemma, it follows that \begin{align*}
\int_0^t Y_{n_k} (s) dM(s) \to \int_0^t Y(s) dM(s) \text{ almost surely}
\end{align*}
and uniformly on bounded $t$ sets. Moreover, the uniformity of the convergence yields that the limit has continuous paths. 
\\\\
These lines of reasoning have also shown that the limit is independent of the choice of the approximating sequence $(Y_n)_{n \in \mathbb{N}}$ we have made at the beginning of the proof. 
\\\\
To check that the limit above is also a square integrable martingale and that 
\begin{align*}
\left( \int_0^t Y(s) dM(s) \right)^2 - \int_0^t Y^2(s) dA(s)
\end{align*}
is also a martingale it is enough to notice that the convergence $Y_n \to_\mathcal{H} Y$ implies both
\begin{align*}
\int_0^t Y_n(s) dM(s) \to \int_0^t Y(s) dM(s) \text{ and } \int_0^t Y_n^2(s)dA(s) \to \int_0^t Y^2(s) dA(s)
\end{align*}
in $L^1$ and $L^2$ respectively, because of the isometry shown in Corollarly \ref{corisometry}. This permits passage to the limit in the conditional expectations relevant to the verify the martingale property in the two cases. 
\end{proof}
\newpage
\subsection{Itô's formula and applications}
Itô's formula is a central identity used in stochastic comptations and a version of the fundamental theorem of calculus having an extra term involving the second derivative. 

\begin{thm}[Itô's formula] \label{itosformula}
Let $f: \mathbb{R} \to \mathbb{R}$ be a $C^2$-function satisfiying
\begin{align*}
\mathbb{E}\left( \int_0^t [f'(M(s))]^2 dA(s) \right) < \infty \text{ and } 
\mathbb{E}\left( \int_0^t \mid f"(M(s))\mid dA(s) \right) < \infty
\end{align*}
Then we have the identity
\begin{align*}
f(M(t))-f(M(0))= \int_0^t f'(M(s)) dM(s) + \frac{1}{2} \int_0^t f"(M(s)) dA(s). \quad (\star)
\end{align*}
\end{thm}
\noindent For the proof of this Theorem we need to extend the concept of the variance process to the one of \textit{covariance processes} associated with \textit{two} martingales:
\begin{thm}
Given two square integrable continuous martingales $M_1(t)$, $M_2(t)$; there exists a unique continuous \textit{covariance process}, denoted by \\
$\langle M_1,M_2\rangle_t$, of bounded variation such that $\langle M_1,M_2\rangle_0=0$ and 
\begin{align*}M_1(t) M_2(t)-\langle M_1(t),M_2(t) \rangle_t \quad \text{is a martingale.}
\end{align*}
\end{thm}

\begin{proof}
The uniqueness can be proven as in the proof of the Theorem \ref{variancethm} for the variance processe, and the existence can be shown by polarization.
\end{proof}
\noindent We are now in a position to present a sketch of the proof of Theorem \ref{itosformula}.
\begin{proof}
By localization, it is enough to prove the result for uniformly bounded martingales satisfying $\lvert M(s) \rvert \leq K$ and $\langle M,M\rangle_s\leq K$ for all $0\leq s \leq t$ and some constant $K$.\\
\\
The equation $(\star)$ follows immediately in the case that $f(x)=x$. %By FTC?
Using induction on $k \in \mathbb{N}$ one can show that it also holds for $f(x)=x^k$ and is therefore true for any $f$ being polynomial.
The idea in the inductive step is to assume that the statement holds for $f(x)=x^k$ and showing that is is also true for $g(x)=x f(x)$ using the integration by parts formula and the identity (won't be proven here)
% Das chömmer so leider nöd stoh lah :(

\begin{center} %MARCO!!! Wie chanmer das schöner darstelle? :(
For $M_1(t), M_2(t)$ bounded and conituous martingales, one has:
$M_1(t) M_2(t)=M_1(0) M_2(0) + \int_0^t M_1(s) dM_2(s) + \int_0^t M_2(s) dM_1(s) + \langle M_1,M_2\rangle_t$
\end{center}
Using $M_1(t)=M(t)$ and $M_2(t)= \int_0^t f'(M(s)) dM(s)$ one can conclude the result for $f$ being polynomial.\\
For the general case you have to choose polynomials $f_n$ such that $f_n$ and its two first derivatives converge to $f$ and its first two derivatives are unfiformly bounded on $[-K,K]$. %??? uniformly bounded? typo in script?
To pass to the limit one can now use the last statement of Theorem \ref{thminequalty}.
\end{proof}
\end{document}