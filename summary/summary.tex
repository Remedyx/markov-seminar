\documentclass[11pt,a4paper, final]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage[UKenglish]{isodate}

\newtheorem{lem}{Lemma}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{cor}{Corollary}[section]

\newtheorem{defn}{Definition}[section]
\newtheorem{exmp}{Example}[section]
\theoremstyle{definition}
\newtheorem{rem}{Remark}[section]

\renewcommand\thesection{\arabic{section}}



\begin{document}
\thispagestyle{empty}
\tableofcontents
\newpage
\section{Conditional Expectation}
We start with some preliminaries, things known or less known.
\\\\
Let $( \Omega, \mathcal{F}, \mathbb{P})$ be a probability space
\begin{defn} We define the Lebesgue spaces \\ $L^p(\Omega, \mathcal{F}, \mathbb{P})=L^p= \lbrace X: \Omega \to \mathbb{R} \mid X \text{ is $\mathcal{F}$  measurable and } \mathbb{E}(|X|^p) < \infty \rbrace$ where $1 \leq p < \infty$. \\
$L^\infty = \lbrace X : \Omega \to \mathbb{R} \mid X \text{ is $\mathcal{F}$ measurable and } \exists C>0 : \mathbb{P}(|X| \leq C) = 1  \rbrace  $ is the space of almost surely bounded random variables. 
\end{defn}
\begin{thm}[Hölder's inequality] Let $X \in L^P, Y \in L^q$ for conjugate $p,q \geq 1$ (i.e. $1/p + 1/q = 1$) then we have $XY \in L^1$ moreover Hölder's inequality holds true
\begin{align*}
\mathbb{E}(|XY|) \leq \mathbb{E}(|X|^p)^{\frac{1}{p}} \mathbb{E}(|X|^q)^{\frac{1}{q}}
\end{align*}
\end{thm}
\begin{rem} \ \begin{enumerate}
\item Hölder's inequality is the reason why probability theory behaves "nicer" in consideration of Lebesgue spaces, i.e. let $0<r<s$ and set $p= \frac{s}{r}$ then for the conjugate $q=\frac{p}{p-1}$ we can apply Hölder's inequality to $|X|^r$ and the constant $1$ function. 
\begin{align*}
\mathbb{E}(|X|^r) \leq \mathbb{E}(|X|^{rp})^{1/p} = \mathbb{E}(|X|^s)^{r/s} \implies \mathbb{E}(|X|^r)^{\frac{1}{r}} \leq \mathbb{E}(|X|^s)^{\frac{1}{s}} 
\end{align*}
in particular if $X$ is a random variable such that $X \in L^s$ then it always follows that $X \in L^r$ for any $r <s$. In general measure theory, where the spaces don't need to be of finite measure, this is not the case at all. 
\item It is an important Theorem of Riesz that states that for all $1 \leq p \leq \infty$ the $L^p$ spaces are complete, in particular they are Banach spaces. Especially for $p=2=q$ the space $L^2$ is even a Hilbert space. 
\end{enumerate}
\end{rem}
\begin{prop}[Jensen's inequality] Let $X \in L^1$ and $\varphi: \mathbb{R} \to \mathbb{R}$ a convex function, then we have 
\begin{align*}
\varphi( \mathbb{E}(X)) \leq \mathbb{E}( \varphi(X))
\end{align*}
\end{prop}
\begin{prop}[Existence of the conditional expection] Let $\mathcal{G} \subset \mathcal{F}$ be a subsigma-algebra. We define $Z= \mathbb{E}(Z \mid \mathcal{G})$ to be the unique $\mathcal{G}$-measurable variable such that 
\begin{align*}
\mathbb{E}(Z 1_A) = \mathbb{E}(X 1_A) \text{ for all } A \in \mathcal{G}
\end{align*}
\end{prop}
\newpage
\subsection{Weak convergence of measures}
Weak convergence is one of many types of convergence relating to the convergence of measures. It depends on a topology on the underlying space and thus is not a purely measure theoretic notion. 
\\\\
There are several equivalent definitions of weak convergence of a sequence of measures, some of which are more general than others. The equivalence of these conditions is sometimes known as the Portmanteau theorem. It is an Exercise of Exercise Sheet 4 to prove this theorem.
\\\\
Let $\mathcal{X}$ be a metric space and let it be endowed with its Borel $\sigma$-Algebra $\Sigma$. Let $\mathcal{M}( \mathcal{X})$ denote the space of all probability measures on $\mathcal{X}$. 
\begin{defn} A sequence of probability measures $( \mu_n)_{n \in \mathbb{N}}$ converges weakly to $\mu$ in $\mathcal{M}( \mathcal{X})$ if for all $f \in C_b( \mathcal{X} \to \mathbb{R})$ we have
\begin{align*}
\int f d \mu_n \to \int f d \mu, \text{ as } n \to \infty. \tag{*}
\end{align*}
We then simply denote this convergence by $\mu_n \implies \mu$. 
\end{defn}
\begin{rem}With this mode of convergence, we increasingly expect to see the next outcome in a sequence of random experiments becoming better and better modeled by a given probability distribution. Moreover, convergence in distribution or weak convergence is, as the name suggests, the weakest form of convergence. 
\end{rem}
\noindent 
\textbf{Exercise 4.5. (Portmanteau's theorem)} The following assertions are equivalent:

\begin{enumerate}
\item $\mu_n \implies \mu$.
\item (*) holds for all $f \in UC_b( \mathcal{X} \to \mathbb{R})$ (i.e. bounded uniformly contin. $f$).
\item $\liminf \mu_n(O) \geq \mu (O)$ for all open sets $O \subset \mathcal{X}$. 
\item $\limsup \mu_n(A) \leq \mu (A)$ for all closed sets $A \subset \mathcal{X}$. 
\item $\lim \mu_n(B) = \mu(B)$ for all measurable sets $B \subset \mathcal{X}$ such that $\mu(B^\circ)= \mu( \overline{B})$. 
\end{enumerate}
\noindent In the case when we specialize $\mathcal{X}= \mathbb{R}$, with its usual topology, then we have the following two more applicable criteria. 
\begin{thm}[Lévy's continuity theorem] Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of random variables and let $\varphi_n(t):= \mathbb{E}(e^{itX_n})$ for $t \in \mathbb{R}$ denote the characteristic function. We then have $X_n \implies X$ if and only if $\varphi_n(t) \to \varphi(t)$. 

\end{thm}
\begin{prop} Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of random variables, then $X_n \implies X$ if and only if $\mathbb{P}(X_n \leq x) \to \mathbb{P}(X_n \leq x)$ for all continuity points of $x \mapsto \mathbb{P}(X \leq x)$. 

\end{prop}

\newpage
\section{Discrete time Martingales}
\begin{defn} Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, an increasing sequence of $\sigma$-algebras $\mathcal{F}_0 \subset \mathcal{F}_1 \subset \mathcal{F}_2 \subset \cdots \subset \mathcal{F}$ is called a filtration on $\Omega$. We call the space $(\Omega, \mathcal{F}, (\mathcal{F})_{n \in \mathbb{N}}, \mathbb{P})$ a filtered probability space. 
\end{defn}
\begin{defn} A stochastic process $X=(X_n)_{n \in \mathbb{N}}$ is called adapted if $X_n$ is $\mathcal{F}_n$-measurable for all $n \in \mathbb{N}$. Moreoever, an adapted process is called a martingale if $X_n \in L^1$ for all $n \in \mathbb{N}$ and 
\begin{align*}
\mathbb{E}(X_n \mid \mathcal{F}_m) = X_{n \wedge m } \text{ for all } n,m \geq 0 
\end{align*}
\end{defn}
\begin{rem} Analogeously we define sub-martingales if instead of an equality we have $\geq$ above, or a super-martingale for $\leq$ respectively. 
\end{rem}
\begin{defn} A stopping time $T$ is a random variable $T: \Omega \to \mathbb{N}_0^\infty$ such that $\lbrace T \leq n \rbrace \in \mathcal{F}_n$ for all $n \in \mathbb{N}$. The sigma-algebra at the stopping time $T$ is then defined as
\begin{align*}
\mathcal{F}_T := \lbrace A \in \mathcal{F}: A \cap \lbrace T \leq n \rbrace \in \mathcal{F}_n \text{ for all } n \in \mathbb{N} \rbrace 
\end{align*}
\end{defn}
\begin{rem} The sigma algebra at the stopping time $T$ $\mathcal{F}_T$ encodes the information up to the random time $T$. In other words, if we interprete our filtered probability space as an random experiment, then the maximum information that can be found until the random time $T$ is in $\mathcal{F}_T.$
\end{rem}
\begin{thm}[Optional stopping theorem - weak version] Let $X$ be a martingale. Let $X^T:=(X_n^T)_{n \in \mathbb{N}}$ be given by $X_n^T:= X_{n \wedge T}$ then $X^T$ is also a martingale. Moreover if $S, T$ are almost surely finite stopping times with $S \leq T$ almost surely, then
\begin{align*}
\mathbb{E}(X_T \mid \mathcal{F}_S) = X_S
\end{align*}
\end{thm}
\begin{thm}[Martingale convergence Theorem] Let $X$ be a super-martingale that is bounded in $L^1$ (i.e. $\sup_{n \in \mathbb{N}} \mathbb{E}(|X_n|) < \infty$). Then there exists a random variable $X_\infty \in L^1$ such that $X_n \to X_\infty$ almost surely, moreover 
\begin{align*}
\mathbb{E}(|X_\infty|) \leq \sup_{n \in \mathbb{N}} \mathbb{E}(|X_n|)
\end{align*}
\end{thm}
\begin{cor} Let $X$ be a super-martingale that is bounded from below (i.e. $X_n \geq c$ a.s. for some $c \in \mathbb{R}$ for all $n \in \mathbb{N}$). Then $X_n$ converges almost surely to $X_\infty \in L^1$. 
\end{cor}
\begin{thm}[Behaviour of Martingales with bounded increments] Let $X=(X_n)_{n \in \mathbb{N}}$ be a martingale with bounded increments (i.e. $|X_{n+1}-X_n| \leq C$). Let $\mathcal{C}:= \lbrace \limsup X_n = \liminf X_n \in \mathbb{R} \rbrace$ , $\mathcal{O}:= \lbrace \limsup X_n = + \infty \rbrace \cap \lbrace \liminf X_n = - \infty \rbrace $, then $\mathbb{P}( \mathcal{O} \cup \mathcal{C}) = 1$.  
\end{thm}
\begin{lem}[Doob's inequalities] Let $X$ be a non-negative submartingale and $X_n^*:= \max_{k \leq n} X_k$ for $n \in \mathbb{N}$, then we have for any $\lambda >0$
\begin{align*}
\lambda \mathbb{P}(X_n^* > \lambda)  \leq \mathbb{E}(X_n 1_{X_n^* > \lambda})  \leq \mathbb{E}(X_n) 
\end{align*}
In addition, for $p > 1$, we have
\begin{align*}
\|X_n^*\|_p \leq \frac{p}{p-1} \| X_n \|_p 
\end{align*}
\end{lem}
\begin{thm}[Closed martingale convergence theorem] Let $X$ be a martingale and $p>1$. Then the following statements are equivalent:
\begin{enumerate}
\item $\sup_{n \in \mathbb{N}} \|X_n\|_p < \infty$ 
\item $X_n$ converges almost surely and in $L^p$ to $X_\infty \in L^p$ 
\item There exists a random variable $X_\infty \in L^p$ such that 
\begin{align*}
\mathbb{E}(X_\infty \mid \mathcal{F}_n) = X_n \text{ for all } n \in \mathbb{N}
\end{align*}
\end{enumerate}
If any (and consequently all) of these conditions hold true, we say that $X$ is a closed martingale in $L^p.$
\end{thm}
\begin{defn} A family $\mathcal{H}$ of random variables is called uniformly integrable (UI) if 
\begin{align*}
\lim_{\lambda \to \infty} \sup_{X \in \mathcal{H}} \mathbb{E}( |X| 1_{|X| > \lambda} ) = 0 
\end{align*}
\end{defn}
\noindent \textbf{Exercise:} Prove that $\mathcal{H}$ is UI if there exists $G: [0, \infty) \to [0, \infty)$ non-decreasing such that 
\begin{enumerate}
\item $\lim_{t \to \infty} \frac{G(t)}{t} = \infty$ 
\item $\sup_{X \in \mathcal{H}} \mathbb{E}(G(X)) \infty$ 
\end{enumerate}
\begin{thm}[UI convergence Theorem] Let $(X_n)_{n \in \mathbb{N}}$ a stochastic process, then the following statements are equivalent:
\begin{enumerate}
\item $(X_n)_{n \in \mathbb{N}}$ is UI and $X_n \to X_\infty$ in probability.
\item $X_n \to X_\infty$ in $L^1$.
\end{enumerate}
\end{thm}
\begin{thm}[Characterisation of UI martingales through closedness] Let $X$ be a martingale. The following assertions are equivalent:
\begin{enumerate}
\item $X$ is UI. 
\item $X$ converges almost surely and in $L^1$ to $X_\infty \in L^1.$ 
\item There exists $X_\infty \in L^1$ such that $\mathbb{E}(X_\infty \mid \mathcal{F}_n) = X_n$, i.e. the martingale is closed. 
\end{enumerate}
\end{thm}
\begin{thm}[Optional stopping - strong version] Let $X$ be a closed (and thus UI) martingale. Then for any stopping times $S$ and $T$, one has 
\begin{align*}
\mathbb{E}(X_T \mid \mathcal{F}_S)= X_{T \wedge S}
\end{align*}
\end{thm}
\newpage
\begin{defn} Let $\mathcal{F}$ be a sigma-algebra and consider a sequence \\ $\dots \subset \mathcal{H}_2 \subset \mathcal{H}_1 \subset \mathcal{F}$ of sigma-algebras (i.e. we lose information over time). Let $Y_1 \in L^p( \Omega, \mathcal{H}_1, \mathbb{P})$ for some $p \in [1, \infty)$. Then $Y=(Y_n)_{n \in \mathbb{N}}$ is called a backward-martingale if $Y_n= \mathbb{E}(Y_1 \mid \mathcal{H}_n)$ for all $n \in \mathbb{N}$. 
\end{defn}
\begin{thm}[Convergence theorem for backward-martingales] \ \newline Let $Y=(Y_n)_{n \in \mathbb{N}}$ be a backward-martingale. Then $Y$ converges almost surely and in $L^p$ to $Y_\infty = \mathbb{E}(Y_1 \mid \mathcal{H}_\infty )$ where $\mathcal{H}_\infty = \cap_{n \in \mathbb{N}} \mathcal{H}_n$. 
\end{thm}
\begin{thm}[Kolmogorov's Law of Large Numbers] Let $(\xi_n)_{n \in \mathbb{N}}$ be a sequence of i.i.d. random variables with $\xi_1 \in L^1$. Let $S_n = \xi_1 + \dots + \xi_n$ be the simple random walk, then we have
\begin{align*}
\frac{S_n}{n} \to \mathbb{E}(X_1) \text{ almost surely and in } L^1
\end{align*}
\end{thm}
\begin{proof}
\textbf{Exercise 2.4.} Kolmogorov's LLN can be shown in it's full generality (i.e. for $L^1$ RV) by using backwards martingales and Kolomogorov's 0-1 Law. 
\end{proof}
\begin{thm}[Kolmogorov's 0-1 Law] Let $(\xi_n)_{n \in \mathbb{N}}$ be a sequence of i.i.d. random variables and let $\mathcal{H}_n = \sigma( \xi_j : j \geq n )$. Then, the sigma algebra $\mathcal{H}_\infty := \bigcap_{n \in \mathbb{N}} \mathcal{H}_n$ is trivial, i.e. for every event $A \in \mathcal{H}_\infty$ we have  \\ $\mathbb{P}(A) \in \lbrace 0 ,1 \rbrace$. 
\end{thm}
\noindent Next we will remind the very important Borel-Cantelli Lemmas. We recall the following definiton. Let $(A_n)_{n \in \mathbb{N}}$ be a sequence of events in a probability space $( \Omega, \mathcal{F}, \mathbb{P})$ then we define 
\begin{align*}
A & = \limsup_{n \to \infty} A_n:= \bigcap_{n=1}^\infty \bigcup_{i \geq n}^\infty A_i = \lbrace A_n \text{ infinitely often} \rbrace  
\\
A^c &:= \liminf_{n \to \infty} A_n := \bigcup_{n=1}^\infty \bigcap_{i \geq n }^\infty A_i = \lbrace A_n \text{ eventually} \rbrace 
\end{align*}
We remark that the following is true
\begin{align*}
\omega \in \bigcap_{n=1}^\infty \bigcup_{i \geq n}^\infty A_i &\iff \forall n \in \mathbb{N}, \exists i \geq n : \omega \in A_i   \\
\omega \in \bigcup_{n=1}^\infty \bigcap_{i \geq n }^\infty A_i &\iff \exists n \in \mathbb{N}, \forall i \geq n : \omega \in A_i
\end{align*}
\begin{thm}[Borel-Cantelli Lemma 1] If $\sum_{n \in \mathbb{N}} \mathbb{P}(A_n) < \infty$, then we have $\mathbb{P}(A_n \text{ i.o.} )=0$.
\end{thm}
\begin{thm}[Borel-Cantelli Lemma 2] If the events $A_n$ are independent and $\sum_{n \in \mathbb{N}} \mathbb{P}(A_n) = \infty$, then we have $\mathbb{P}( A_n \text{ i.o.} ) = 1$ 
\end{thm}
\newpage
\begin{thm}[Extension of Borel Cantelli Lemma] Let $\mathcal{F}= (\mathcal{F}_n)_{n = 1}^\infty$ be a Filtration and suppose $A_n \in \mathcal{F}_n$, then we have
\begin{align*}
 \lbrace A_n \text{ i.o.}\rbrace = \left \lbrace \sum_{n \geq k} \mathbb{P}(A_n \mid \mathcal{F}_{n-1} ) = \infty \right \rbrace 
\end{align*}
for all $k \in \mathbb{N}$ up to a set of measure zero. 
\end{thm}
\noindent We now give some results that are related to the Central Limit Theorem (CLT). We will first recall the classical result.
\begin{thm}[CLT] Let $X_1, X_2, \dots$ be a sequence of i.i.d. $L^2$ random variables with $\mathbb{E}(X)= \mu$ and Var$(X)= \sigma^2 >0$. Let $S_n= X_1 + \dots + X_n$, then we have
\begin{align*}
\frac{S_n-n \mu }{\sqrt{n} \sigma} \implies \mathcal{N}(0,1) 
\end{align*}
\end{thm}
\noindent It is our goal to generalize this result, i.e. weaken the conditions (in particular get rid of i.i.d.) and then give a central limit theorem for martingales. 
\\\\
The outline is the following: Let $\lbrace X_{n,k} : 1 \leq k \leq J(n), n \in \mathbb{N}_{ \geq 1 } \rbrace$ be an array of centered random variables. Here $K$ can be random, however it is almost surely finite with $J(n) \to \infty$ as $n \to \infty$.  
\\\\
Let $( \xi_j)_{j \in \mathbb{N}}$ be a sequence of centered i.i.d. random variables, we then set 
\begin{align*}
X_{n,k} = \frac{\xi_k}{\sqrt{n}}
\end{align*}
Suppose that $X_{n,k} \in L^2( \mathcal{F})$ and let \begin{align*}
S_n := \sum_{k=1}^{J(n)} X_{n,k}
\end{align*}
\begin{thm}[Mc Leish CLT] In the situation as above, let us define \\ $T_n = \prod_{k=1}^{J(n)} (1 + it X_{n,k})$ and suppose that
\begin{enumerate}
\item $T_n$ is UI and $\mathbb{E}(T_n) \to 1$ as $n \to \infty$.
\item $ \sum_{k=1}^{J(n)} X_{n,k}^2 \to 1$ in Probability.
\item $\max_{k \leq n} |X_{n,k}| \to 0$ in Probability. 
\end{enumerate}
Then $S_n \implies \mathcal{N}(0,1)$ as $n \to \infty$. 
\end{thm}
\newpage
\begin{thm}[Martingale Central Limit Theorem] Let $X_{n,k}$ where $1 \leq k \leq m_n$ ($m_n$ is deterministic with $m_n \to \infty$ as $n \to \infty$) be a $\mathcal{F}_{n,k}$-measurable martingale difference array. Suppose that 
\begin{enumerate}
\item $\mathbb{E}(X_{n,k} \mid \mathcal{F}_{n,k-1}) = 0$ (Martingale difference property)
\item $V_n:= \sum_{j=1}^{m_n} X_{n,j}^2 \to 1$ in Probability.
\item (Lindenberg Condition) For any $\epsilon >0$ we have that 
\begin{align*}
\lim_{n \to \infty}  \sum_{k=1}^n \mathbb{E}(X_{n,k}^2 1_{ | X_{n,k}| > \epsilon}) = 0 
\end{align*}
\end{enumerate}
Then we have as $n \to \infty$ 
\begin{align*}
S_n=  \sum_{k=1}^{m_n} X_{n,k} \implies \mathcal{N}(0,1) 
\end{align*}
\end{thm}
\newpage
\section{Stochastic processes}
Let $(H_i)_{i \in I}$ be a sequence of complete, separable metric spaces, where $I$ is an arbitrary index set.
\begin{defn}[Product space] We define the product topology for the product space $H= \prod_{i \in I} H_i$ to be the coarsest (that is the weakest/smallest) topology such that all the maps $\pi_i: H \to H_i$ are continuous. 
\end{defn}
\begin{rem} \ \begin{enumerate}
\item This construction is equivalent to the construction of the weak topology. 
\item This guarantees that the Borel $\sigma$-Algebra $\mathcal{B}(H)$ coincides with the product $\sigma$-algebra
\begin{align*}
\sigma \left( \left\{ \prod_{i \in I} A_i : A_i \in \mathcal{B}(H_i) \text{ for } i \in K, A_i = H_i \text{ for } i \notin K, K \subset F \text{ finite} \right\} \right) 
\end{align*}
\end{enumerate}
that is, the product $\sigma$-algebra on $\mathbb{R}^\mathbb{N}$ is generated by 
\begin{align*}
\bigcup_{n=1}^\infty \{ A_1 \times A_2 \times \cdots \times A_n \times \mathbb{R} \times \mathbb{R} \times \cdots \mid A_1, \dots , A_n \in \mathcal{B}(\mathbb{R}) \} 
\end{align*}
\end{rem}
\begin{defn}[Product measure] Let $\mu_i$ be a probability measure on $H_i$, we define the product measure $\mu = \bigotimes_{i \in I} \mu_i$ on $H$ to be the unique measure such that 
\begin{align*}
\mu \left( \prod_{i \in I} A_i \right) = \int 1_{ \prod_{i \in I} A_i } d \mu = \prod_{i \in I} \mu_i (A_i) 
\end{align*}
This implies that 
\begin{align*}
\int \prod_{j \in K} f_j ( \pi_j ( \omega)) \mu (d \omega) = \prod_{j \in K} \int f_j d \mu_j, \text{ for all } f_j \in L^1(H_j , \mathcal{B}(H_j), \mu_j) 
\end{align*}
under the assumption that $A_i \in \mathcal{B}(H_i)$ for $i \in K$ and $A_i=H_i$ for $i \notin K$. 
\end{defn}
\noindent
It is by no means clear that such a unique product measure exists at all, this is however part of the celebrated Kolmogorov Extension theorem which we will state next.
\newpage
\begin{thm}[Kolmogorov's Extension Theorem] Let $K \subset I$ be a finite subset and let $\mu_K$ be a probability measure on $\prod_{i \in K} H_i$. Suppose that for any $K \subset J$ where $J$ is another finite subset of $I$ the following consistency condition holds:
\begin{align*}
\mu_J \left( \prod_{i \in J} A_i\right) = \mu_K \left( \prod_{i \in K} B_i \right), \text{ with } A_i = \begin{cases} B_i \in \mathcal{B}(H_i), & \text{ if } i \in K \\
H_i, & \text{ if } i \notin K  \end{cases}
\end{align*}
Then there exists a unique measure on the product space $H= \prod_{i \in I} H_i$ such that for all finite subsets $K \subset I$ one has 
\begin{align*}
\mu \left( \prod_{i \in I} A_i \right) = \mu_K \left( \prod_{i \in K } B_i \right), \text{ with } A_i = \begin{cases} B_i \in \mathcal{B}(H_i), & \text{ if } i \in K \\
H_i, & \text{ if } i \notin K \end{cases}
\end{align*}
\end{thm}
\begin{rem} \ \begin{enumerate} \item Here $( \mu_K)_{K \subset I, K \text{ finite} }$ is called the collection of finite dimensional marginal distributions of $\mu$.
\item Kolmogorov extension theorem says that, given the finite dimensional marginales $( \mu_K)$ as above, if they satisfy the consistency condition as requested in the theorem, then there exists a unique extension $\mu$ to the whole product space $H$ with marginale $(\mu_K)$. 
\item The Theorem is also known as Kolmogorov's existence theorem or Kolmogorov's consistency theorem. It guarantees that a suitably "consistent" (here consistency is meant as in the theorem) collection of finite-dimensional distributions will define a stochastic process. In particular the theorem is essential to guarantee the existence of Probability measures on uncountable product spaces. 
\end{enumerate}
\end{rem}
\begin{defn} A stochastic process $X=(X_i)_{i \in I}$,  where $I$ is an arbitrary index sex, is a collection of random variables defined on the same probability space $( \Omega, \mathcal{F}, \mathbb{P})$, i.e. $X_i : \Omega \to H_i$ is $\mathcal{F}$-measurable. \\ The law of $X$ is a probability measure $ \mu$ on $H= \prod_{i \in I} H_i$ such that for all finite $K \subset I$, the marginal law $\mu_K$ of $\mu$ is given by  
\begin{align*}
\mu_K \left( \prod_{j \in K} A_j \right) = \mathbb{P}( X_j \in A_j, j \in K) \text{ for all } A_j \in \mathcal{B}(H_j) 
\end{align*}
\end{defn}
\begin{rem} We can always choose $( \Omega, \mathcal{F}, \mathbb{P}) = ( H = \prod_{i \in I} H_i, \mathcal{B}(H), \mu)$, then we have $X_i = \pi_i$ where $\pi_i$ are the coordinate maps, i.e.
\begin{align*}
\pi_i : \begin{cases} H & \longrightarrow H_i \\ \omega & \longmapsto \omega_i  \end{cases}
\end{align*}
This is sometimes called the \textit{canonical process}. 
\end{rem}
There is a section about the Galton-Watson process, it is an important exercise and will be left open on this summary. 
\newpage 
\subsection{Relevant Exercises}
These Exercises are related to stochastic processes and are from Exercise Sheet 3. In the following let $\mathcal{B}$ denote the Borel $\sigma$-algebra on the unit interval $[0,1]$ and let $\lambda$ be the Lebesgue measure on $[0,1]$. \\
\\
\textbf{Exercise 3.1.} Construct on the probability space $([0,1], \mathcal{B}, \lambda)$ a sequence of independent Bernoulli random variables, that is a measurable map $X: [0,1] \to \lbrace 0,1 \rbrace^\mathbb{N}$ whose law is the appropriate product measure.
\\\\
\textbf{Exercise 3.2.} Construct on the probability space $([0,1], \mathcal{B}, \lambda)$ a sequence of independent random variables uniformly distributed on $[0,1]$. Then, deduce that for any sequence of probability measures $( \mu_n)_{n \in \mathbb{N}}$ on $\mathbb{R}$, there exists a stochastic process $X$ with law $\otimes_{n=1}^\infty \mu_n$. 
\\\\
\textbf{Exercise 3.4.} Show that on the probability space $([0,1], \mathcal{B}, \lambda)$ there can be no process $(X_t)_{t \geq 0}$ such that the $X_t$ are i.i.d. Bernoulli $1/2$ random variables. Why isn't this a contradiction to Kolmogorov's Extension Theorem?
\\\\
The next Exercise is from Exercise Sheet 5 and rather tough. 
\\\\
We define the standad $n$-dimensional Gaussian measure $\gamma_n$ to be the probability with density with respect to the Lebesgue measure $\lambda_n$ on $\mathbb{R}^n$ given by 
\begin{align*}
\dfrac{d \gamma_n}{d \lambda_n}(x) = \dfrac{e^{-|x|^2/2}}{(2 \pi)^{n/2}}, \text{ for all } x \in \mathbb{R}^n 
\end{align*}
\textbf{Exercise 5.6.} * Show that the sequence of probability measures $( \gamma_n)_{n=1}^\infty$ satisfies the Kolmogorov consistentcy condition and deduce that there exists a probability measure $\Gamma$ on $\mathbb{R}^\mathbb{N}$ such that if $X \sim \Gamma$, then $X=(X_1, X_2, \dots )$ is a sequence of independent, identically distributed stnadard Gaussian random variables. 
\newpage
\section{Markov Processes}
\begin{defn}
A stochastic process $(X_t)_{t \in I}$ is a Markov process if for all \\ $f: \mathcal{H} \to \mathbb{R}_+$ measurable ($\mathcal{H}$ is a metric space) and for all $s <t$ we have 
\begin{align*}
\mathbb{E}(f(X_t) \mid \mathcal{F}_s^X ) = \mathbb{E}(f (X_t) \mid \sigma (X_s)), \text{ where } \mathcal{F}_s^X := \sigma ( X_t : t \leq s )  
\end{align*}
\end{defn}
\begin{defn} A process $(X_n)_{n \in \mathbb{N}}$ is a time-homogenous Markov chain if there exists a measurable map $Q: \mathcal{H} \to \mathcal{M}( \mathcal{H}):= \lbrace \text{probability measures on } \mathcal{H} \rbrace$ such that $\mathbb{P}(X_n \in A \mid X_{n-1} = x ) = Q(x,A)$ for all Borel sets $A \subset \mathcal{H}$. We call $Q$ the transition probability of the Markov chain. $\mathcal{H}$ is called the state space of the Chain, moreover $x \in \mathcal{H}$ is called a state of the chain. 
\end{defn}
\noindent \textbf{Exercise 5.1.} Let $( \xi_n)_{n \in \mathbb{N}}$ be a sequence of i.i.d. real-valued random variables with common law $\mu$. Let $F: \mathbb{R} \times \mathbb{R} \to \mathbb{R}$ be a measurable map. Show that the process given by 
\begin{align*}
X_n:= F(X_{n-1}, \xi_n)
\end{align*}
is a time-homogenous Markov chain on $\mathbb{R}$ and find its transition probability. Is the converse of this statement true? I.e. does every time-homogenous Markov chain admit such a representation?
\begin{prop} $\mathcal{M}( \mathcal{H})$ equipped with the topology of weak convergence is a completely metrizable, separable space. 
\end{prop}
\noindent Recall that a sequence $\mu_n \in \mathcal{M}( \mathcal{H})$ converges weakly to $\mu \in \mathcal{M}( \mathcal{H})$ if and only if 
\begin{align*}
 \int f d \mu_n \to \int f d \mu, \text{ for all } f \in C_b ( \mathcal{H} \to \mathbb{R})
\end{align*}
\noindent Given $Q$ as above, then there exists a Markov chain with $\mathbb{P}_\nu ( X_0 \in A) = \nu (A)$ and transition probability $Q$. We define for all $n  \in \mathbb{N}$ 
\begin{align*}
\mathbb{P}_\nu ( x_0 \in A_0 , x_1 \in A_1, \dots , x_n \in A_n ) = \int \limits_{A_0 \times \cdots \times A_n} \nu (dx_0) Q(x_0,dx_1) \dots Q(x_{n-1}, dx_n)
\end{align*}
By Kolmogorov's extension theorem, there exists a unique probability measure $\mathbb{P}_\nu$ on $( \Omega, \mathcal{F}_\infty)$, where $\mathcal{F}_\infty = \bigvee_{n=1}^\infty \mathcal{F}_n$ is the product $\sigma$-algebra on $\Omega$, with marginal distribution as above. 
\\\\
We now consider the case where $\Omega = \mathcal{H}^\mathbb{N}= \lbrace  \omega = ( \omega_0, \omega_1, \dots ) : \omega_i \in \mathcal{H} \rbrace$ is the so called configuration space. The coordinate process $X_n( \omega)= \omega_n$ is a Markov Chain w.r.t. the canonical Filtration $\mathcal{F}_n = \sigma( \omega_0, \omega_1, \dots , \omega_n)$.  
\begin{defn} We define the shift operator acting on $\Omega$ by $\Theta :\Omega \to \Omega$, $\Theta(\omega)=( \omega_1, \omega_2, \omega_3, \dots )$ where $\omega=( \omega_0, \omega_1, \dots )$. \\ We then have $\Theta^n( \omega) = ( \omega_{n+j})_{j=0}^\infty$ for all $n \in \mathbb{N}$.
\end{defn}
\begin{thm}[Weak Markov Property] Under $\mathbb{P}_\nu$, conditionally on the canonical filtration $\mathcal{F}_n= \sigma( \omega_0, \omega_1, \dots , \omega_n)$, $\Theta^n ( \omega)$ has law given by $\mathbb{P}_{\omega_n}$ and is independent of $\mathcal{F}_{n-1}$ for all $n \in \mathbb{N}_{ \geq 1}$. 
\end{thm}
\begin{thm}[Strong Markov Property] Let $X$ denote a Markov Chain. Let $T$ be a stopping time such that $\mathbb{P}_\nu (T < \infty) >0 $. Conditionally on the event $\lbrace T < \infty \rbrace$ and $\mathcal{F}_T$ we have that $\Theta^T (X)$ is a Markov Chain with law given by $\mathbb{P}_{X_T}$ and independent of $\mathcal{F}_{T-1}$.
\end{thm}
Let be $\mathcal{H}$ a countable/finite state space, the transition probability $Q$ is then represented as a matrix, i.e. we have 
\begin{align*}
Q(x,A) = \sum_{y \in A} Q_{xy}, \text{ for all } x \in \mathcal{H}
\end{align*}
A probability measure on $\mathcal{H}$ is a vector such that we have 
\begin{align*}
 \nu (A) = \sum_{y \in A} \nu_y 
\end{align*}
We have 
\begin{align*}
\mathcal{M}( \mathcal{H}) = \lbrace \mu \in \mathbb{R}^\mathcal{H} : \mu_x \geq 0 \text{ for all } x \in \mathcal{H} \text{ and } \sum_{x \in \mathcal{H}} \mu_x = 1 \rbrace 
\end{align*} 
\begin{defn} We define for all $x \in \mathcal{H}$
\begin{align*}
R_x &:= \inf \lbrace n \geq 1 : \omega_n = x \rbrace \text{, i.e. the first return to the state $x$.} \\
N_x &:= \# \lbrace n \geq 0 : \omega_n =x \rbrace, \text{ i.e. the number of visits of the state $x$.}
\end{align*}
A state $x \in \mathcal{H}$ is called recurrent if $\mathbb{P}_x ( R_x < \infty ) =1$, else $x$ is called transient. 
\end{defn}
\begin{prop} If $x$ is recurrent, then $\mathbb{P}(N_x = \infty) =1$. \\  If $x$ is transient, then we have 
\begin{align*}
\mathbb{E}_x ( N_x)= \frac{1}{\mathbb{P}_x(R_x = \infty)} < \infty 
\end{align*}
\end{prop}
\begin{defn} The Green Kernel of the Markov Chain is defined as
\begin{align*}
G_{xy}:= \mathbb{E}_x ( N_y) = \sum_{n \in \mathbb{N}} Q_{xy}^n = \sum_{n \in \mathbb{N}} \mathbb{P}_x ( \omega_n =y) 
\end{align*}
i.e. the expected number of visits of $y$ starting from the state $x$. \\ (Recall that $Q_{xy}^n = \mathbb{P}_x( \omega_n =y)$.)
\end{defn}
\newpage 
\begin{prop} Let $x,y \in \mathcal{H}$, $x \neq y$, then the following holds
\begin{enumerate}
\item $G_{xx}= \infty$ if and only if $x$ is recurrent.
\item $G(x,y)=0$ if and only if $\mathbb{P}_x (R_y < \infty) =0$. 
\\  (i.e. impossible to go from $x$ to $y$.)
\item If $\mathbb{P}_x( R_y < \infty) >0$, then $G(x,y)= G(y,y) \mathbb{P}_x( R_y < \infty)$.
\end{enumerate}
\end{prop}
\begin{proof}
See Exercises!
\end{proof}
\begin{cor}
Let $R:= \lbrace x \in \mathcal{H} : \mathbb{P}_x ( R_x < \infty) = 1 \rbrace$ the set of recurrent states. We have that if $x \in R$ and $G(x,y) > 0$, then $y \in R$ and also $G(y,x)>0,  \ \mathbb{P}_y(R_x < \infty ) =1$. 
\end{cor}
\begin{defn} Let $x,y \in \mathcal{H}$ be two states. We say that $x$ and $y$ communicate if $\mathbb{P}_x(R_y< \infty)>0$ and $\mathbb{P}_y(R_x < \infty)>0$. Alternatively, thanks to the above Proposition we can say, $x$ and $y$ communicate if $G(x,y) >0$ and $G(y,x) >0$. 
\end{defn}
\begin{rem} \ \begin{enumerate} \item  We define an equivalence relation on $R$ by $x \sim y$ if $G(x,y) >0$ or equivalently thanks to the above Proposition $x \sim y$ if $\mathbb{P}_x(R_y < \infty)>0$. The above corollarly yields that this indeed defines an equivalence relation on $R$. We have $R = \cup_{j \in I} R_j$ and the sets $R_j$ are disjoint, the $R_j$'s are called the recurrence classes.  It follows that for $x \in R_j$, then $G(x,y) >0$ if and only if $y \in R_j$.
\item Alternatively we can say that "communicates with" defines an equivalence relation on the set $R$. 
\end{enumerate}
\end{rem}
\noindent \textbf{Exercise 5.3. **} We define the simple random walk on $\mathbb{Z}^d$ to be the Markov process with transition probability given by 
\begin{align*}
Q_{x,y} = 2^{-d} 1_{|x-y|=1}, \text{ for all } x,y \in \mathbb{Z}^d
\end{align*}
Compute the Green function $G_{00}$ for the simple random walk on $\mathbb{Z}^d$. Deduce that the walk is recurrent if and only if $d \leq 2$. 
\newpage 
\begin{thm}[Classification of states] The following holds true
\begin{enumerate}
\item If $x \in R_j$ for some $j \in I$, then 
\begin{align*}
\begin{cases} \mathbb{P}_x ( N_y = \infty) = 1, & \text{ for all } y \in R_j \\ 
\mathbb{P}_x ( N_y = 0) = 1, & \text{ for all } y \notin R_j \end{cases}
\end{align*}
\item Let $T= \inf \lbrace n \geq 0 : \omega_n \in R \rbrace$ be the first time when the Markov Chain meets the recurrent states. Assume that $x$ is transient, i.e. $x \notin R$, then one of the following applies:
\begin{enumerate}
\item  $T= \infty$ and we have $\mathbb{P}_x(N_y < \infty) =1$ for all $y \in \mathcal{H}$. 
\item $T < \infty$ and there exists a random index $J$ such that $\theta^T(\omega) \in R_J$. 
\end{enumerate}
\end{enumerate}
\end{thm}
\begin{rem} The Theorem states if we start in a recurrence class $R_j$, then we will visit every state in the same recurrence class infinitely often and every state outside of said class not even once. In particular this means that our Markov Chain is stuck in said recurrence class. 
\\\\
On the other hand, if we start with a transient state $x \notin R$, then either we will never meet the set of recurrent states $R$ (i.e. we stay in the space of transient states) and in this case $\mathbb{P}_x$-almost surely we will only meet every $y \in \mathcal{H}$ finitely many times, or the chain eventually meets a certain recurrence class $R_J$ and then gets stuck there. 
\end{rem}
\begin{defn} The chain is called irreducible if $G_{xy} > 0$ for all $x,y \in \mathcal{H}$, i.e. all states of the chain communicate.  
\end{defn}
\begin{rem}Irreducibility means that either we have $R= \mathcal{H}$ or $R= \emptyset$. Indeed if all states communicate, then if one states is recurrent $(G_{xx}= \infty$) then all states are recurrent, also if one state is transient, then consequently all states are transient. In particular we only have one recurrence class $\mathcal{H}=R$ or we have that $R= \emptyset$. We formulate this in the next corollary. 
\end{rem}
\begin{cor} If the chain is irreducible, one of the following applies
\begin{enumerate}
\item All states are recurrent, in particular $\mathbb{P}_x( N_y = \infty, \text{ for all } y \in \mathcal{H} \rbrace = 1$ for all $x \in \mathcal{H}$.
\item All states are transient, in particular $\mathbb{P}_x( N_y < \infty, \text{ for all } y \in \mathcal{H} \rbrace = 1$ for all $x \in \mathcal{H}$. 
\end{enumerate}
\end{cor}
\newpage
\subsection{Stationary measures $\&$ the Ergodic Theorem}
In this important section we introduce stationary measures, they play an important role when we introduce our 2 central results, namely the ergodic theorem and the asymptotic behaviour of a Markov chain. \\\\
We consider a Markov Chain with transition probability $Q$. 
\begin{defn} Let $\mu$ be a non-trivial measure on $\mathcal{H}$ such that $\mu_x< \infty$ for all $x \in \mathcal{H}$. We say that $\mu$ is stationary if $\mu = \mu Q$.  That is
\begin{align*}
\mu (x) =  \sum_{y \in \mathcal{H}} \mu(y) Q(y,x), \text{ for all } x \in \mathcal{H}
\end{align*}
\end{defn}
\begin{defn} We say that $\mu$ is reversible if it satisfies the detailed balance, i.e. 
\begin{align*}
\mu_x Q_{xy} = \mu_y Q_{yx}, \text{ for all } x,y \in  \mathcal{H}
\end{align*}
\end{defn}
\noindent \textbf{Exercise 6.6.}: Check that if $\mu$ is reversible, then it is also stationary. 
\begin{lem} Let $z \in R$ and define for all $x \in \mathcal{H}$
\begin{align*}
\hat{\pi}(x):= \sum_{n=0}^\infty \mathbb{P}_z ( \omega_n =x, R_z >n ) = \mathbb{E}_z \left( \sum_{n=0}^{R_z-1} 1_{ \omega_n=x} \right)
\end{align*}
Then $\hat{\pi}$ is a stationary measure and we have $\hat{\pi}(x) >0 $ if and only if $x \sim z$ i.e. $G_{zx}>0$. 
\end{lem}
\begin{prop} If the chain is irreducible the solution $\mu = \mu Q$ is unique up to a multiplicative constant. 
\end{prop}
\begin{proof}
Exercise! 
\end{proof}
\begin{thm} Assume that the chain is irreducible and recurrent. Then we have the following dichotomy. 
\begin{enumerate}
\item The chain is positive recurrent, i.e. there exists a unique stationary measure with finite mass. Moreover we then have, the probability measure $ \pi_x = 1/ \mathbb{E}_x(R_x)$ is stationary, $\pi$ is called the equilibrium measure. 
\item The chain is null recurrent, i.e. all stationary measures have infinite mass. Moreover we then have, $\mathbb{E}_x(R_x) =  \infty$ for all $x \in \mathcal{H}$. 
\end{enumerate}
\end{thm}
\begin{prop} Assume the chain is irreducible $(G_{xy} >0)$ and there exists a equilibrium measure $\pi$. Then the chain is positive recurrent, in particular $\pi$ is unique. 
\end{prop}
\newpage
\begin{thm}[Ergodic Theorem] Let $f,g: \mathcal{H} \to \mathbb{R}_+.$ and $z \in R$. Assume that $\int f d \hat{\pi} < \infty$ and $g(x) >0$ for some $x \sim z$. Then we have $\mathbb{P}_z$-almost surely
\begin{align*}
\dfrac{\sum_{j=0}^n f( \omega_j)}{\sum_{j=0}^n g( \omega_j)} \to \dfrac{\int f d \hat{\pi}}{\int g d \hat{\pi}} \text{ as } n \to \infty 
\end{align*}
Moreover, if the chain is positive recurrent then we have 
\begin{align*}
\frac{1}{n} \sum_{j=0}^n f( \omega_j) \to \int f d \pi, \text{ as } n \to \infty
\end{align*}
where $\pi$ is the (unique) equilibrium measure. 
\end{thm}
\begin{proof}
We first show the second part of the statement. To this extend let $g \equiv 1$, then we have $\int g d \hat{\pi}= \hat{\pi}( \mathcal{H})< \infty$ because the chain is positive recurrent, also $\sum_{j=1}^n g( \omega_j) = n$, thus we obtain 
\begin{align*}
\frac{1}{n} \sum_{j=0}^n f( \omega_j) \to \frac{1}{\hat{\pi}(\mathcal{H})}  \sum_{y \in \mathcal{H}} f(y) \hat{\pi}(y) = \sum_{y \in \mathcal{H}} f(y) \pi(y), \text{ where } \pi(y) = \frac{\hat{\pi}(y)}{\hat{\pi}(\mathcal{H})}
\end{align*}
To show the more general statement, we first discuss the idea. The idea behind the proof is that we divide the path of $X=( \omega_i)_{i=0}^\infty$ at the times when $\omega_i=z$ (where $z \in \mathcal{H}$ is our recurrent state) and we consider the resulting sequence of i.i.d. random variables (they are i.i.d. thanks to the strong Markov Property), then finally we apply Kolmogorov's LLN to obtain the statement. We now implement this idea:
\\\\
Without loss of generality (we will discuss at the very end of the proof why this is the case) we let $g(y)= 1_{ \lbrace z=y \rbrace}$, in this setup we get that 
\begin{align*}
\sum_{j=0}^n g( \omega_j)= \# \lbrace j \leq n : \omega_j = z \rbrace.
\end{align*}
Let now $T_0:=0, T_1= R_z, \dots , T_{n+1}:= inf \lbrace i > T_n : \omega_j = z \rbrace$ a sequence of finite stopping times (as discussed above, dividing the MC at the recurrent state $z$). Thanks to the strong Markov Property we have that \begin{align*}
\xi_n := \sum_{j= T_n}^{T_{n+1}-1} f( \omega_j), \text{ defines an i.i.d. seq. of RV}.
\end{align*}
We compute
\begin{align*}
\mathbb{E}( \xi_0)&= \mathbb{E}_z \left( \sum_{j=0}^{T_1-1} f( \omega_j) \right) = \mathbb{E}_z \left( \sum_{j=0}^{R_z-1} f( \omega_j) \right) 
 = \mathbb{E}_z \left( \sum_{j=1}^{R_z-1} \sum_{y \in \mathcal{H}} f(y) 1_{ \lbrace \omega_j = y \rbrace} \right) \\ & \overset{\text{pos.}}= \sum_{y \in \mathcal{H}} f(y) \mathbb{E}_z \left( \sum_{j=1}^{R_z-1} 1_{ \lbrace \omega_j =y \rbrace} \right)  
 = \sum_{y \in \mathcal{H}} f(y) \hat{\pi}(y) =: \hat{\pi}(f)
\end{align*}
\newpage
Thanks to Kolmogorov's LLN we get that \begin{align*}
\frac{\xi_0 + \dots + \xi_n}{n+1} \to \hat{\pi}(f), \text{ a.s. as n} \to \infty 
\end{align*}
But since we also have 
\begin{align*}
\sum_{j=0}^{T_{n+1}-1} g( \omega_j) = \# \lbrace j +1 \leq T_{n+1} : \omega_j = z \rbrace = n+1
\end{align*}
and 
\begin{align*}
\int g d \hat{\pi} &= \int_{ \mathcal{H}} 1_{ \lbrace z \rbrace } (y) d \hat{\pi }= \hat{\pi}(z) = \mathbb{E}_z \left( \sum_{n=0}^{R_z-1} 1_{ \omega_n = z } \right)= \mathbb{E}_z( 1_{ \omega_0 = z } ) \\ 
& = \mathbb{P}_z ( \omega_0 =z ) = 1,
\end{align*}
we have therefore actually shown 
\begin{align*}
\dfrac{\sum_{j=0}^{T_{n+1}-1} f( \omega_j)}{\sum_{j=0}^{T_{n+1}-1} g( \omega_j)} = \dfrac{\sum_{j=0}^{T_{n+1}-1} f( \omega_j)}{n+1} \to \frac{\hat{\pi}(f)}{1} = \frac{\hat{\pi}(f)}{ \int g d \hat{\pi}}, \text{ a.s.}
\end{align*}
that is, we have proven the statement for the sequence of stopping times $(T_n)_{n \in \mathbb{N}}$. \\
\\
Clearly, we always have $T_k \leq n < T_{k+1}$ for all $n \in \mathbb{N}$ and since $f \geq 0$ we thus have 
\begin{align*}
\frac{\sum_{j=0}^{T_k-1}f ( \omega_j)}{k} \leq \frac{\sum_{j=0}^n f( \omega_j)}{n} \leq \frac{\sum_{j=0}^{T_{k+1}-1}f( \omega_j)}{k+1}
\end{align*}
then if $n \to \infty$, we have in particular that $k \to \infty$ and the statement follows because both sides converge to the desired result, as we have already established.
\\\\
We finally discuss the w.l.o.g.-argument that we assumed at the beginning of the proof. Let $h: \mathcal{H} \to \mathbb{R}_+$ be general with $\hat{\pi}( \mathcal{H}) < \infty$, then we have already shown that 
\begin{align*}
\frac{\sum_{i=0}^n f( \omega_i)}{\sum_{i=0}^n g( \omega_i)} \to \frac{\hat{\pi}(f)}{\hat{\pi}(g)}, \text{ almost surely}
\end{align*}
but also 
\begin{align*}
 \frac{\sum_{i=0}^n h( \omega_i)}{\sum_{i=0}^n g( \omega_i)} \to \frac{\hat{\pi}(h)}{\hat{\pi}(g)}, \text{ almost surely}.
\end{align*}
Taking now the quotient (cancellation) and letting $n \to \infty$ gives the general statement. 
\end{proof}
\begin{cor} The following holds 
\begin{enumerate}
\item If the chain is positive recurrent, then for $\mu \in \mathcal{M}( \mathcal{H})$ one has $\mathbb{P}_\mu$ almost surely that 
\begin{align*}
\frac{1}{n} \sum_{j=0}^n f( \omega_j) \to \int f d \pi, \text{ as } n \to \infty 
\end{align*}
where $\pi$ is the equilibrium measure. 
\item If the chain is null-recurrent, then for any $\mu \in \mathcal{M}( \mathcal{H})$ one has $\mathbb{P}_\mu$ almost surely that 
\begin{align*}
\frac{1}{n} \sum_{j=0}^n 1_{ \omega_j = x } \to 0, \text{ as } n \to \infty \text{ for all } x \in \mathcal{H}.
\end{align*}
\end{enumerate}
\end{cor}
\begin{defn} Let $x \in R$ be a recurrent state and consider the set \\  $P_x:= \lbrace n \in \mathbb{N}_{ \geq 1} : Q_{x,x}^n >0 \rbrace$. This set is then infinite (because $x$ is recurrent) and the period of $x$ is defined to be the greatest common divisor of the set $P_x$. That is, the period of $x$ is the number $d= \gcd P_x$. A state $x$ is called aperiodic if $d=1$, else it is called periodic with period $d$. A Markov chain is called aperiodic if every state is aperiodic. 
\end{defn}
\begin{prop} A chain is aperiodic if and only if there exists a positive integer $k >0$ such that $Q_{xy}^k >0$ for all $x,y \in \mathcal{H}$.
\end{prop}
\begin{prop} Let $X$ be an irreducible markov chain, then all states $x$ have the same period $d$. In particular for an irreducible chain it is enough to find one recurrent state with period $d=1$ to conclude that the chain is aperiodic. 
\end{prop}
\begin{thm}[Asymptotic behaviour of a MC] Suppose the chain is positive recurrent and aperiodic, then 
\begin{align*}
\sum_{x \in \mathcal{H}} | \mathbb{P}_z( \omega_n =x) - \pi (x) | \to 0, \text{ as } n \to \infty 
\end{align*}
i.e. the law of $\omega_n$ under $\mathbb{P}_z$ converges in total variation to $\pi$. 
\end{thm}
\begin{rem} Convergence in total variation is a very strong convergence, in particular it follows that the law of $\omega_n$ converges to the equilibirum measure $\pi$ in distribution as $n \to \infty$. 
\end{rem}
\newpage
\noindent \textbf{Exercise 6.1. *} Let $Q$ be an irreducible transition matrix and assume that the chain has a stationary measure which is finite. Show that the chain is positive recurrent. 
\\\\
\textbf{Exercise 6.2.} Let $Q$ be a transition matrix of an irreducible recurrent chain. Show that $\widehat{Q}= \epsilon I + (1- \epsilon) Q$ is also a transition matrix for any $0 < \epsilon < 1$ and that the corresponding chain is irreducible and aperiodic. 
\begin{thm} Let $Z=(Z_k)_{k \in \mathbb{N}}$ identically distributed random variables such that
\begin{enumerate}
\item $\mathbb{E}(Z_k^2)=1$ 
\item $\mathbb{E}(Zk \mid \mathcal{F}_{k-1}) = 0$ where $\mathcal{F}_k = \sigma (Z_1, \dots , Z_k)$
\item $Z$ is ergodic, in this regime this means 
\begin{align*}
\frac{1}{n} \sum_{j=1}^n f(Z_j) \to \mathbb{E}(f(Z)), \text{ almost surely, for all integrable $f$}.
\end{align*}
\end{enumerate}
Then we have that
\begin{align*}
\frac{Z_1 + \dots + Z_n}{\sqrt{n}} \implies \mathcal{N}(0,1), \text{ as } n  \to \infty 
\end{align*}
\end{thm}
\begin{proof}
Follows by McLeish CLT.
\end{proof}
\begin{cor} Let $\mathcal{H}$ be a finite state space and $Q$ be an irreducible transition Matrix with equilibrium measure $\pi$. If $\int f d  \pi =0$ and $\sigma^2 = \int f^2 d \pi <  \infty$ then we have that 
\begin{align*}
\frac{1}{\sqrt{n}} \sum_{j=1}^n f ( \omega_j) \implies \mathcal{N}(0, \sigma^2), \text{ as } n  \to \infty 
\end{align*}
\end{cor}
\newpage
\section{Ergodicity}
In this section we consider $H$ to be a complete, separable metric space with Borel $\sigma$-algebra $\mathcal{F}$. For all $t \in \mathbb{R}$ let $T_t : H \to H$ be a family of bijective measurable transformations such that they satisfy the semigroup property, i.e.
\begin{align*}
\begin{cases} T_t \circ T_s = T_{t+s} \\ T_0(x) = x \end{cases}
\end{align*}
\begin{defn} Let $\mu$ be a measure on $H$. We say that $\mu$ is an invariant measure if $\mu (T_t^{-1}(A))= \mu (A)$ for all $A \in \mathcal{F}$ and for all $t \in \mathbb{R}$. \\  $(H, \mathcal{F},  \mu , T_t) $ is called a dynamical system. 
\end{defn}
\begin{defn} $\mu$ is called ergodic if for every $A \in \mathcal{F}$ with $T_t^{-1}(A)=A$ for all $t \in \mathbb{R}$ we have  $\mu(A) \in \lbrace 0 ,1 \rbrace $. 
\end{defn}
\noindent We consider the functional expression
\begin{align*}
R_t(f) = \frac{1}{t} \int_0^t f(T_sx)ds, \text{ for } f : H \to \mathbb{R} \text{ measurable}
\end{align*}
and we wonder under what conditions we have that $R_t(f) \to \int f d \mu$ as $t \to \infty$ and for which $\mu$? We start by discussing some functional analytic properties.
\begin{defn} A unitary operator is a bounded linear operator $U: H \to H$ on a Hilbert space $H$ that satisfies the following:
\begin{enumerate}
\item $U$ is surjective, and 
\item $U$ preserves the inner product of the Hilbert space $H$. That is we have 
\begin{align*}
\langle Ux, Uy \rangle_H = \langle x, y \rangle_H, \text{ for all } x,y \in H. 
\end{align*}
\end{enumerate}
\end{defn}
\begin{lem} Let $U_s : L^2(H, F, \mu)=:H \to H$ be defined as $H_sf(x)=f(T_sx)$ for all $s \in \mathbb{R}$. Then $U_s$ is an unitary operator on $L^2( \mu)$.
\end{lem}
\begin{lem} If $U$ is a unitary operator on a Hilbert space $H$, then we have ran$(I-U)^\perp = \ker(I-U)$ where $I: H \to H$ is the identity operator. 
\end{lem}
\begin{thm}[Von Neumann Ergodic Theorem] Let $U$ be a unitary operator on a Hilbert space $H$. Let $P$ be the orthogonal projection on $\ker(I-U)$. Then we have for all $x \in H$ 
\begin{align*}
\lim_{n \to \infty} \frac{1}{n} \sum_{k=1}^n U^k f = Pf \text{ in H}
\end{align*}
\end{thm}
\begin{rem} The convergence above is of course meant with respect to the norm in $H$ which is induced by the scalar product that is given on $H$. 
\end{rem}
\begin{lem} Let us define $\mathcal{I}:= \lbrace A \in \mathcal{F} : T_t^{-1}(A) = A \text{ for all } t \in \mathbb{R} \rbrace$, then $\mathcal{I}$ is a $\sigma$-algebra, it is called the $\sigma$-algebra of invariant sets. Moreover, $f: H \to \mathbb{R}$ is $\mathcal{I}$-measurable if and only if $f \circ T_t = f$. 
\end{lem}
\begin{proof}
Exercise! (Exercise 7.6)
\end{proof}
\begin{cor} Let $\mu$ be an invariant measure under $(T_t)_{t \in \mathbb{R}}$, $\mathcal{I}$ the $\sigma$-algebra of invariant sets as above, then we have 
\begin{align*}
\lim_{t \to \infty} \frac{1}{t} \int_0^t f (T_s \omega) ds = \mathbb{E}^\mu(f \mid \mathcal{I}) \text{ in } L^2( \mu).
\end{align*}
\end{cor}
\noindent Next we discuss the Poincaré recurrence theorem, for dynamical systems it states that  after a sufficiently long but finite time the system will return to a state very close to the initial state. 
\\\\
Let $\Omega$ be a separable complete metric space and $\theta: \Omega \to \Omega$ be a continuous map with a continuous inverse (i.e. a Homeomorphism). Let $\mu$ be an invariant probability measure on $\Omega$, that is $\mu$ satisfies $\mu( \theta^{-1} A)= \mu(A)$ for all $A \in \mathcal{B}( \Omega)$. We then call $( \Omega, \theta, \mu)$ a dynamical system. 
\begin{thm}[Poincaré recurrence Theorem] Given a dynamical system as above. For any $A \in \mathcal{B}(\Omega)$ we have for $\mu$ almost all $x \in A$, that $\theta^n(x) \in A$ infinitely often. 

\end{thm}
\begin{proof}
Exercise 7.5. !
\end{proof}
\begin{defn} A dynamical system $( \Omega, \theta, \mu)$ is called mixing if for any $A,B \in \mathcal{B}( \Omega)$ we have
\begin{align*}
\lim_{n \to \infty} \mu(\theta^{-n}( A \cap B)) = \mu(A) \mu(B)
\end{align*}
\end{defn}
\begin{prop} Show that a dynamical system $( \Omega, \theta, \mu)$ is ergodic if and only if 
\begin{align*}
\lim_{n \to \infty} \frac{1}{n} \sum_{k=0}^{n-1} \mu( \theta^{-k}( A \cap B)) = \mu(A) \mu(B)
\end{align*}
Deduce that mixing implies ergodicity. 
\end{prop}
\begin{proof}
Exercise! (Exercise 8.1)
\end{proof}
\noindent \textbf{Exercise 8.4.} Let $( \Omega, \theta, \mu_1)$ and $( \Omega, \theta, \mu_2)$ be two ergodic dynamical systems. Show that if $\mu_1 \neq \mu_2$, then these two measures are mutually singular. 
\newpage
\section{Continuous time Martingales}
\begin{defn} Let $X=(X_t)_{t \in T}$ be a stochastic process on some filtered probability space $( \Omega, \mathcal{F}, ( \mathcal{F}_t)_{t \in T}, \mathbb{P})$. Then we say that $X$ is a martingale if  
\begin{enumerate}
\item $X$ is $\mathcal{F}_t$-adapted, i.e. $X_t$ is $\mathcal{F}_t$-measurable for all $t \in T$.
\item $X_t$ is $\mathbb{P}$-integrable for all $t \in T$. 
\item $\mathbb{E}(X_t \mid \mathcal{F}_s) = X_s$ for all $s < t$.
\end{enumerate}
\end{defn}
\begin{defn} Let $(X_t)_{t \geq 0}$ and $(Y_t)_{t \geq 0}$ be stochastic processes. We say 
\begin{enumerate}
\item $X_t$ and $Y_t$ are indistinguishable if  $\mathbb{P}(X_t = Y_t, \text{ for all } t \in \mathbb{R}_0^+)=1$
\item $X_t$ is a modification of $Y_t$ (and vice versa) if $\mathbb{P}(X_t=Y_t)=1$ for all $t \in \mathbb{R}_0^+$ 
\item $X_t$ and $Y_t$ have the same FDD (Finite Dimensional Distributions) if for all $n \in \mathbb{N}$ and for all $H \in \mathcal{B}( \mathbb{R}^n)$ we have 
\begin{align*}
\mathbb{P}( (X_{t_1}, \dots , X_{t_n}) \in H ) = \mathbb{P}( (Y_{t_1}, \dots , Y_{t_n}) \in H)
\end{align*}
\end{enumerate}
\end{defn}
\begin{rem} We do indeed have that $1) \implies 2) \implies 3)$. 
\end{rem}
\begin{defn} Let $(\mathcal{F}_t)_{t \geq 0}$ be a Filtration. We define the left respectively right continuous Filtrations as 
\begin{align*}
\mathcal{F}_{t^-}:= \bigvee_{s <t} \mathcal{F}_s \text{ and } \mathcal{F}_{t^+} := \bigcap_{s >t} \mathcal{F}_s
\end{align*}
\end{defn}
\begin{rem} We have the inclusions $\mathcal{F}_{t^-} \subset \mathcal{F}_t \subset \mathcal{F}_{t^+}$ for all $t \in \mathbb{R}_0^+$ and it is very well possible that these inclusions are proper/strict. 
\end{rem}
\begin{defn} Let $(\mathcal{F}_t)_{t \geq 0}$ be a Filtration. We define
\begin{align*}
\tilde{\mathcal{F}}_t := \sigma ( \mathcal{F}_{t^+}, \mathcal{N}), \text{ where } \mathcal{N} \text{ is the set of $\mathbb{P}$-negligible sets}. 
\end{align*}
We say that our Filtration $( \mathcal{F}_t)_{t \geq 0}$ satisfies the usual conditions if $\mathcal{F}_t = \tilde{\mathcal{F}}_t$ for all $t \in \mathbb{R}_0^+$.
\end{defn}
\noindent We come now to our main result in this section. It states that we can regulate martingales, i.e. represent them as modifications through cadlag (continue a droite, limites a gauche) martingales. 
\begin{thm}[Martingale regularization theorem] \ \\ Let $(X_t)_{t \geq 0}$ be a $ \mathcal{F}_t$-martingale, then there exists $(\widetilde{X_t})_{t \geq 0}$ a $\widetilde{\mathcal{F}_t}$-martingale which is cadlag such that $X_t = \mathbb{E}( \widetilde{X_t} \mid \mathcal{F}_t) $ almost surely for all $t \geq 0$. \\
Moreover, if $(\mathcal{F}_t)_{t \geq 0}$ satisfies the usual conditions, then $\widetilde{X_t}$ is a cadlag modification of $X_t$. 
\end{thm}
\newpage
\noindent The Martingale regularization theorem is a powerful tool when it comes to extending statements we already know from discrete time martingales to continuous time martingales, because we can regularize them by cadlag representations and then approximate them (using for instance that $\mathbb{Q}$ is dense in $\mathbb{R}$). 
\begin{thm}[Convergence Theorem] Let $X$ be a cadlag martingale with respect to $( \mathcal{F}_t)_{t \geq 0}$. If $X$ is bounded in $L^1$, i.e. if $\sup_{t \geq 0} \| X_t \|_{L^1} < \infty$, then $X_t \to X_\infty$ as $t \to \infty$ for some $X_\infty \in L^1( \Omega, \mathcal{F}_\infty, \mathbb{P})$. \\
Moreover if $X$ is UI, then $X_t \to X_\infty$ in $L^1( \Omega, \mathcal{F}, \mathbb{P})$. 
\end{thm}
\begin{proof}
Exercise! (Exercise 9.3.)
\end{proof}
\begin{thm}[Stopping Theorem] Let $X$ be a cadlag martingale and let $\tau \leq \Lambda$ be stopping times with respect to $( \mathcal{F}_t)_{t \geq 0}$. If $\Lambda \leq C$ for some constant $C >0$, then 
\begin{align*}
\mathbb{E}(X_\Lambda \mid \mathcal{F}_\tau ) = X_\tau \tag{$\star$}
\end{align*}
Moreover, if $X$ is UI, then $(\star)$ above is true for all stopping times $\tau \leq \Lambda.$ 
\end{thm}
\begin{proof}
Exercise!
\end{proof}
\newpage
\section{Brownian Motion}
Before we introduce Brownian Motion we start with some preliminary reminders that might be useful later on. 
\begin{defn} Let $X$ be a real valued random variable, we say that $X$ is standard Gaussian and denote this by $X \sim \mathcal{N}(0,1)$ if its probability density function is given by 
\begin{align*}
f(x) = \frac{1}{\sqrt{2 \pi}} \exp \left( \frac{-x^2}{2} \right), \text{ for all } x \in \mathbb{R}.
\end{align*}
\end{defn}
\noindent The concept of a standard Gaussian (also known as normal) random variable can be extended to the multivariate i.e. the vector case. 
\begin{defn} A random vector $X=(X_1, \dots , X_n), \ n \in \mathbb{N}$ is said to have the multivariate Gaussian distribution if every linear combination of its components $Y=a_1 X_1 + \dots + a_n X_n$ where $a_i \in \mathbb{R}$ for all $i \in \mathbb{N}$ is standard Gaussian distributed (i.e. Gaussian in dimension 1). 
\end{defn}
\noindent We extend the definition of the mean and covariance of a random vector in the most natural way
\begin{defn} Let $X=(X_1, \dots , X_n), \ n \in \mathbb{N}$ be a random vector in $L^2$ (that is by definition that all its components are in $L^2)$ then we define the mean of $X$, $\mathbb{E}(X):= ( \mathbb{E}(X_1), \dots , \mathbb{E}(X_n))$ and its Covariance/Dispersion Matrix $D=(D_{i,j})_{1 \leq i,j \leq n }$ where $D_{i,j} := \text{Cov}(X_i, X_j) := \mathbb{E}(X_i X_j)- \mathbb{E}(X_i)\mathbb{E}(X_j)$. We notice that the Covariance Matrix is symmetric. 
\end{defn}
\begin{thm} Let $X$ be a Gaussian vector (i.e. $X$ has the multivariate Gaussian distribution), then the law of $X$ is fully characterized by its mean and its covariance matrix as defined above. 
\end{thm}
\noindent We are now ready to start on the relevant definitions in order to introduce what a Brownian motion is. 
\begin{defn} A stochastic process $X=(X_t)_{t \geq 0}$ is Gaussian if for every $n \in \mathbb{N}_{ \geq 1}$ and times $t_1, \dots , t_n  \in [0,  \infty)$ the vector $(X_{t_1}, \dots , X_{t_n})$ has a multivariate Gaussian distribution. 
\end{defn}
\begin{rem} \ \begin{enumerate}
\item A Gaussian process $X$ is fully characterized by its mean $\mathbb{E}(X_t)$ and by its covariance kernel $K(t,t'):= \text{Cov}(X_t, X_{t'})= \mathbb{E}(X_t X_{t'})- \mathbb{E}(X_t) \mathbb{E}(X_{t'})$ 
\item If $\mathbb{E}(X_t)=0$, then we have $K(t,t')=\text{Cov}(X_t, X_{t'})=\mathbb{E}(X_tX_{t'})$
\end{enumerate}
\end{rem}
\newpage 
\begin{prop}[Characterization] \label{charbmprop} The following two statements are equivalent:
\begin{enumerate}
\item $(X_t)_{t \geq 0}$ has stationary, independent increments and $X_t \sim \mathcal{N}(0,t)$ for all $t \geq 0$.
\item $(X_t)_{t \geq 0}$ is a Gaussian process with mean zero and covariance kernel $\mathbb{E}(X_t X_{t'}) = t  \wedge t'$ for all $t,t' \in  \mathbb{R}_{0}^+$. 
\end{enumerate}
\end{prop}
\begin{rem} We recall the following
\begin{enumerate}
\item Independence of the increments means that for all times $0 \leq t_1 \leq t_2  \leq \dots \leq t_n< \infty$ where $n \in \mathbb{N}$, $X_{t_n}-X_{t_{n-1}}, \dots , X_{t_3}-X_{t_2}, X_{t_2}-X_{t_1}$ are independent.
\item Stationarity of the increments means that for all $s <t$ we have that $X_t-X_s$ is equal in distribution as $X_{t-s}$. 
\item We can also summarize 1) and 2) above as, if for all $t \in \mathbb{R}_0^+$ we have  \begin{align*}
&(X_{t_n}-X_{t_{n-1}} , \dots , X_{t_3}-X_{t_2}, X_{t_2}-X_{t_1}) \\  &\sim (X_{t+t_n}-X_{t+t_{n-1}} , \dots , X_{t+t_3}-X_{t+t_2}, X_{t+t_2}-X_{t+t_1})
\end{align*} 
\item Since $X_t \sim \mathcal{N}(0,t)$ we have by the stationarity $X_t-X_s \sim X_{t-s} \sim  \mathcal{N}(0,t-s)$. 
\end{enumerate}
\end{rem}
\begin{defn} A Brownian motion is a stochastic process $(B_t)_{t \geq 0}$ with continuous sample paths (i.e. a continuous stochastic process) which satisfies either property 1) or 2) (and consequently both of them) in Propositon \ref{charbmprop}.
\end{defn}
\begin{defn} A Gaussian Hilbert space $W$ is a closed subspace of $L^2( \Omega, \mathcal{F}, \mathbb{P})$ of centered Gaussian Random Variables.
\end{defn}
\begin{defn} A Gaussian process $\Phi$ indexed by a separable Hilbert space $H$ is an isomorphism $\Phi : H \to W$ where $W$ is a Gaussian Hilbert space, such that 
\begin{align*}
\mathbb{E}( \Phi(h) \Phi(g)) = \langle h , g \rangle_H, \text{ for all } h,g \in H. 
\end{align*}
\end{defn}
\newpage
\subsection{Construction of Brownian Motion}
\noindent Here is a sketch of the construction of a Brownian Motion. \\ Let $H= L^2([0, \infty), dx)$ and let $( \varphi_n)_{n \in \mathbb{N}}$ be an ONB of $H$. Let now $\xi_1, \xi_2, \dots $ be a sequence of i.i.d. $\mathcal{N}(0,1)$ random variables. 
\\\\
Let $W:= \overline{\text{span}( \xi_1, \xi_2, \dots )}$, then $W$ is a Gaussian Hilbert space. If we now require that $\Phi: H \to W$ linear satisfies \begin{align*}
\Phi( \varphi_n) = \xi_n, \text{ for all } n \in \mathbb{N}
\end{align*}
Then by linearty of $\Phi$ and the fact that every element $h \in H$ can be written as $h = \sum_{n=1}^\infty \alpha_n \varphi_n$ for some $\alpha_i \in \mathbb{R}$, we get that 
\begin{align*}
\Phi(h) = \sum_{n=1}^\infty \alpha_n \xi_n 
\end{align*}
Consequently $\Phi$ is an isomorphism. Moreover we have that 
\begin{align*}
\mathbb{E}( \Phi(h) \Phi(g)) = \mathbb{E} \left( \sum_{n=1}^\infty \alpha_n \xi_n \sum_{k=1}^\infty \beta_k \xi_k \right) = \sum_{i=1}^\infty \alpha_i \beta_i \mathbb{E}( \xi_i^2) = \sum_{i=1}^\infty \alpha_i \beta_i 
\end{align*}
Analogeously, since $ \varphi_n$ form an ONB of $L^2$ we get that 
\begin{align*}
\langle h, g \rangle_{L^2} = \int_0^\infty \sum_{n=1}^\infty \alpha_n \varphi_n(x) \sum_{k=1}^\infty \beta_k \varphi_k(x) dx = \sum_{i=1}^\infty \alpha_i \beta_i 
\end{align*}
Thus $\Phi$ is a Gaussian process indexed by the Hilbert Space $L^2$. We also notice that $\mathbb{E}( \Phi(h))=0$ and consequently 
\begin{align*}
\mathbb{E} ( ( \Phi(h))^2) = \text{Var}( \Phi(h))= \| h \|_H^2 = \sum_{n=1}^\infty \alpha_n^2 < \infty
\end{align*}
Where the finiteness of the above sum comes from the fact that $\| \cdot \|_{H^2}$ is a well-defined norm on $H=L^2.$ This entails that we have
\begin{align*}
\Phi(h)= \lim_{N \to \infty} \underbrace{\sum_{n=1}^N \alpha_n \xi_n}_{ \sim \mathcal{N}(0, \sum_{n=1}^N \alpha_n^2)} \sim \mathcal{N}\left( 0, \sum_{n=1}^\infty \alpha_n^2 \right)
\end{align*}
Using our work done above, we can set $X_t:= \Phi( 1_{[0,t]})$ and following our calculations above, it is obvious to conclude that $X_t$ is a Gaussian process. Moreover we have 
\begin{align*}
\mathbb{E}(X_t X_s) = \mathbb{E} \left( \Phi(1_{[0,t]}) \Phi(1_{[0,s]}) \right) &= \langle 1_{[0,t]},  1_{[0,s]}  \rangle_{L^2} \\ &= \int_0^\infty 1_{[0,t]}(x) 1_{[0,s]}(x) dx = t \wedge s  
\end{align*}
We have thus shown that the process $X_t = \Phi(1_{[0,t]})$ satisfies 2) in Proposition \ref{charbmprop} and consequently also 1). We are not done yet with the construction, because we need a continuous process. 
\\\\
We are however in a good position to complete the construction. We will consistently use $\Phi$ for the same isomorphism as constructed above. Moreover, we notice that is enough to construct a Brownian Motion on an interval $[0,1]$, by continuity and glueing the functions together we can then extend this to a Brownian Motion on the real line $[0, \infty)$.
\\\\
Consider the Haar function, for this we first define the mother wavelet function as 
\begin{align*}
\Psi (t) := \begin{cases}1, & \text{if } 0 \leq t \leq 1/2 \\
-1, & \text{if } 1/2 \leq t \leq 1 \\ 0, & \text{else} \end{cases}
\end{align*}
We then define for all $n \in \mathbb{N}_0$ and $k=0,1, \dots , 2^n-1$ the Haar function as 
\begin{align*}
\Psi_{n,k}(t) = 2^{n/2} \Psi(2^n t-k), \text{ where } t \in [0,1]
\end{align*}
This function is supported on the dyadic intervals on $[0,1]$, that is on \\ $I_{n,k} = [k 2^{-n}, (k+1)2^{-n}]$ for $k=0, \dots , 2^n-1$ and $n \in \mathbb{N}_0$. Thus we easily conclude that for all $t \in [0,1]$ we have 
\begin{align*}
\left| \int_0^t \Psi_{n,k}(x) dx \right| &\leq \int_0^t | 2^{n/2} \Psi(2^n x-k ) |dx = 2^{n/2} \int_{k2^{-n}}^{(k+1)2^{-n}} |\Psi(2^n x-k)|dx
 \\ &\leq 2^{n/2} \int_{k2^{-n}}^{(k+1)2^{-n}} dx = 2^{n/2} 2^{-n} = 2^{-n/2}
\end{align*}
Furthermore, it is possible to show that $\lbrace 1, \Psi_{n,k} \rbrace_{n \geq 0, k =0, \dots , 2^n-1}$ form an ONB of $L^2([0,1], dx)$. We define now a process by
\begin{align*}
Z_n(t) :=& \sum_{k=0}^{2^n-1} \xi_{n,k} \int_0^t \Psi_{n,k}(x) dx = \sum_{k=0}^{2^n-1} \xi_{n,k} \langle 1_{[0,t]}, \Psi_{n,k} \rangle_{L^2} \\ 
& \text{where } (\xi_{n,k})_{ \substack{ k = 0, \dots , 2^n-1 \\ n \geq 0 }} \text{ is an array of i.i.d. } \mathcal{N}(0,1)
\end{align*}
Then $Z_n$ is continuous in $t \in \mathbb{R}_+$ for all $n \geq 0$. We can estimate 
\begin{align*}
\max_{t \in [0,1]} |Z_n(t)|  &\leq \sum_{k=0}^{2^n-1} | \xi_{n,k} | \left| \int_0^t \Psi_{n,k}(x) dx \right| \\ & \leq \max_{k =0, \dots , 2^n-1} |\xi_{n,k}| \sum_{k=0}^{2^n-1} \left| \int_{k2^{-n}}^{(k+1)2^{-n}} \Psi_{n,k}(x) dx \right|  \\
&\leq \max_k | \xi_{n,k}|  \left| \int_0^1 \Psi_{n,k}(x) dx \right| \leq  \max_{k} | \xi_{n,k} | 2^{-n/2}
\end{align*}
\newpage
Since all the $\xi_{n,k}$ are i.i.d. $\mathcal{N}(0,1)$ we obtain for arbitrary $\lambda >0$ 
\begin{align*}
\mathbb{P}( \max_k | \xi_{n,k}| > \lambda ) \leq 2^n \mathbb{P}( | \mathcal{N}| > \lambda) \leq 2^n \frac{e^{- \lambda^2/2}}{\lambda}
\end{align*}
Let now $\lambda_n = n 2^{-n/2}$ then we obtain by our estimate on the previous page that $\lbrace \max_{t \in [0,1]} | Z_n(t) | > \lambda_n \rbrace \subset \lbrace \max_k | \xi_{n,k} | 2^{-n/2}  > \lambda_n \rbrace$ and consequentaly 
\begin{align*}
\mathbb{P}( \max_{t \in [0,1]}| Z_n(t) | > n 2^{-n/2} ) &\leq  \mathbb{P}( \max_k | \xi_{n,k} | 2^{n/2} > n 2^{n/2} )  = \mathbb{P}( \max_{k} | \xi_{n,k} | >n )  \\
& \leq 2^n \frac{e ^{-n^2/2}}{n}
\end{align*}
By the ratio test, one can easily show that this upper estimate is summable, thus by Borel-Cantelli Lemma we get that eventually 
\begin{align*}
\max_{t \in [0,1]} |Z_n(t) | \leq n 2^{-n/2}
\end{align*}
Again, by the ratio test, this expression is summable and thus we get that 
\begin{align*}
\sum_{n=0}^\infty \max_{t \in [0,1]}  | Z_n(t)| < \infty 
\end{align*}
Since all the $Z_n$ are continuous, and the convergence above is uniformly over all $t \in [0,1]$ this entails that $\sum Z_n(t)$ converges almost surely to a continuous function on $[0,1]$. 
\\\\
We define now 
\begin{align*}
B(t):= t \xi_{0,0} + \sum_{n=1}^\infty  \sum_{k=1}^{2^n-1} \xi_{n,k} \langle 1_{[0,t]}, \Psi_{n,k} \rangle 
\end{align*}
Since $\lbrace 1, \Psi_{n,k} \rbrace_{n \geq 0, k =0, \dots , 2^n-1}$ is an ONB of $L^2([0,1], dx)$ we can write every element $h \in L^2$ as $h = \sum_{ \alpha \in A } \langle x_\alpha, x \rangle x_\alpha.$ We thus have
\begin{align*}
\Phi( 1_{[0,t]}) &= \Phi \left( \sum_{n=0}^\infty \sum_{k=0}^{2^n-1} \langle 1_{[0,t]}, \Psi_{n,k} \rangle \Psi_{n,k}  \right) \\
& = t \xi_{0,0} + \sum_{n=1}^\infty \sum_{k=1}^{2^n-1} \langle 1_{[0,t]}, \Psi_{n,k} \rangle \Phi \left( \Psi_{n,k} \right) \\
& = t \xi_{0,0} + \sum_{n=1}^\infty \sum_{k=1}^{2^n-1} \langle 1_{[0,t]}, \Psi_{n,k} \rangle \xi_{n,k}  = B(t)
\end{align*}
And we have already shown, that $\Psi(1_{[0,t]})$ satisfies ii) and therefore also i), we conclude that $B(t)$ is a Brownian Motion on $[0,1]$. 
\newpage
\begin{defn} The law of a Brownian Motion on $\mathcal{C}:= \lbrace \omega : [0, \infty) \to \mathbb{R} \text{ continuous} \rbrace$ will be denoted by $\mathbb{P}_0$. We denote by $\mathbb{P}_x$ the image of $\mathbb{P}_0$ by the translation map $\Theta: \mathcal{C} \to \mathcal{C}, \ \omega \mapsto \omega + x$ for all $x \in \mathbb{R}$.
\end{defn}
\noindent Brownian Motions have interesting scaling properties as the next Lemma shows.
\begin{lem} Let $B=(B_t)_{t \geq 0}$ be a standard Brownian Motion, then we have 
\begin{enumerate}
\item For any $\alpha \in \mathbb{R}$, $B_{ \alpha^2 t} \sim \alpha B_t$.
\item For any $s >0$ we have that $X_t = B_{s+t}-B_s$ is a Brownian Motion independent of $\mathcal{F}_s^0 = \sigma ( B_t, 0 \leq t \leq s )$. 
\end{enumerate} 
\end{lem}
\begin{proof}
Exercise!
\end{proof}
\begin{defn} We define $\mathcal{F}_s^0 = \sigma ( B_t : 0 \leq t \leq s)$ and $\mathcal{F}_s^+ = \cap_{t >s} \mathcal{F}_t^0$ the right-continuous extension. In particular we call $\mathcal{F}_0^+$ the germ-sigma-algebra. 
\end{defn}
\begin{rem} Notice that $\mathcal{F}_s^+ = \bigcap_{t>s}\mathcal{F}_t^0$ is the sigma-algebra that contains the information of an infinitesimal amount into the future of the BM.
\end{rem}
\begin{thm}[Markov Property] For any bounded measurable $F: \mathcal{C} \to \mathbb{R}$ and any $t >0$ the Markov Property holds, i.e. we have
\begin{align*}
\mathbb{E}_x ( F \circ \Theta_t \mid \mathcal{F}_t^+ ) = \mathbb{E}_{ \omega_t} (F), \ x \in \mathbb{R}
\end{align*}
where $(\Theta_t)_{t \geq 0}$ is the shift on $\mathcal{C}$, i.e. for any $s \in \mathbb{R}$ we have 
\begin{align*}
\Theta_s : \begin{cases} \mathcal{C} & \longrightarrow \mathcal{C} \\
\omega & \longmapsto \theta_s( \omega) = (\omega_{t+s})_{t \geq 0}
\end{cases}
\end{align*}
\end{thm}
\begin{rem} Markov's property for BM states that under $\mathbb{P}_x$, the conditional law of $\Theta_t \omega$ given $\mathcal{F}_t^+$ is $\mathbb{P}_{ \omega_t}$. In particular it states that a BM is independent of the information that exists an infinitesimal amount of time into the future. 
\end{rem}
\begin{proof}
We first start with a remark, we know by the Exercise (Lemma 7.1.) that for all $s>0$ $B_{s+t}-B_s$ is again a standard Brownian Motion that is independent of $\mathcal{F}_s^0 = \sigma (B_t, 0 \leq t \leq s)$. Since the Brownian motion is a continuous process we moreover obtain for any sequence stritly decreasing sequence $(s_n)_{n \in \mathbb{N}}$ with $s_n \downarrow s$ that 
\begin{align*}
B_{s+t}-B_s = \lim_{n \to \infty} B_{s_n + t}-B_{s_n}
\end{align*}
but the right hand side is independent of $\mathcal{F}_{s_n}^0$ and as $s \downarrow s$ therefore the LHS independent of $\mathcal{F}_s^0$. We work now towards a proof of the Theorem in a more abstract/rigoros setting.
\newpage
We can show that for a sequence $(f_n)_{n \in \mathbb{N}}$ of continuous bounded functions $f_i : \mathbb{R} \to \mathbb{R}$ and times $0 < t_1< t_2 < \dots < t_n$ the cylinder functions 
\begin{align*}
Y( \omega) = \prod_{k=1}^n f_k( \omega_{t_k})
\end{align*}
define a continuous function $x \mapsto \mathbb{E}_x(Y)$ for all $x \in \mathbb{R}$. Notice that \begin{align*}
Y( \theta_t \omega) = \prod_{k=1}^n f_k ( \omega_{t_k + t})
\end{align*}
We then obtain
\begin{align*}
\mathbb{E}_x( Y \circ \theta_t \mid \mathcal{F}_{t + \epsilon}^0) &= \mathbb{E}_x \left( \prod_{k=1}^n f_k( \omega_{t + t_k}) \mid \mathcal{F}_{t+ \epsilon}^0 \right) \\
& = \mathbb{E}_x \left( \prod_{k=1}^n f_k( \omega_{t+t_k} - \omega_{t + \epsilon} + \omega_{t + \epsilon}) \mid \mathcal{F}_{t + \epsilon}^0 \right) \\
& = \mathbb{E}_{\omega_{t + \epsilon}} \left( \prod_{k=1}^n f_k( \omega_{t_k - \epsilon}) \right) \overset{ \epsilon \to 0}\longrightarrow \mathbb{E}_{ \omega_t} \left( \prod_{k=1}^n f_k ( \omega_{t_k}) \right) = \mathbb{E}_{ \omega_t}(Y)
\end{align*}
where we used that $\omega_{t+ t_k}- \omega_{t + \epsilon}$ has law of $\mathbb{P}_0$ and is independent of $\mathcal{F}_{t + \epsilon}^0$ and also that $x \mapsto \mathbb{E}_x(Y)$ is continuous with $f_k$ and $\omega_{t_k- \epsilon}$ also continuous. Since $\mathcal{F}_t^+ = \bigcap_{ \epsilon >0} \mathcal{F}_{t + \epsilon}^0$ we obtain from the above 
\begin{align*}
\lim_{ \epsilon \downarrow 0 } \mathbb{E}_x ( Y \circ \theta_t \mid \mathcal{F}_{t + \epsilon}^0 ) = \mathbb{E}_x( Y \circ \theta_t \mid \mathcal{F}_{t}^0 )
\end{align*}
This entails that \begin{align*}
\mathbb{E}_x( Y \circ \theta_t \mid \mathcal{F}_t^+) = \mathbb{E}_{ \omega_t}(Y)
\end{align*}
a monotone class argument lets us generalize this identity to all functions $F : \mathcal{C} \to \mathbb{R}$ measurable and bounded. 
\end{proof}
\noindent A consequence of the Markov's property for BM is given by Blumenthal's 0/1 law, it establishes that the germ sigma algebra is in fact a trivial sigma algebra.
\begin{thm}[Blumenthal's 0/1 law] For any $x \in \mathbb{R}$ and any $A \in \mathcal{F}_0^+$ we have $\mathbb{P}_x(A) \in \lbrace 0,1 \rbrace$, i.e. the germ-sigma-algebra $\mathcal{F}_0^+$ is trivial. 
\end{thm}
\begin{thm}[Strong Markov Property] Let $F: \mathcal{C} \to \mathbb{R}$ be bounded measurable, $\tau$ be a stopping time with respect to $(\mathcal{F}_t^0)_{t \geq 0}$, then for all $x \in \mathbb{R}$ with $\mathbb{P}_x( \tau < \infty) =1$ we have 
\begin{align*}
\mathbb{E}_x( F \circ \Theta_\tau  \mid \mathcal{F}_\tau^+) = \mathbb{E}_{\omega_\tau} ( F)
\end{align*}
\end{thm}
\begin{rem} This means that under $\mathbb{P}_x(  \cdot \mid \tau < \infty)$ the process $t \mapsto \omega_{t + \tau}$ has law $\mathbb{P}_{ \omega_\tau}$ and is indepent from $\mathcal{F}_\tau^+ = \cap_{ \epsilon >0} \mathcal{F}_{\tau + \epsilon}^0$.
\end{rem}
\newpage
\begin{prop}[Reflection principle] Let $a>0$ and $b<a$ be arbitrary, then for any $t>0$ we have 
\begin{align*}
\mathbb{P}_0 \left( \max_{s \leq t} \omega_s >a, \ \omega_t < b \right) = \mathbb{P}_0( \omega_t > 2a-b) = \int_{2a-b}^\infty \dfrac{e^{-x^2/(2t)}}{\sqrt{2 \pi t}} dx 
\end{align*}
\end{prop}
\begin{rem} \
\begin{enumerate}
\item The Reflection principle gives us the joint law of the supremum of the process and the process itself. 
\item The last equality was just stated for the sake of completeness, indeed $\omega_t$ is a Gauss Random variable with mean zero and variance $t$ at time $t$. 
\item For any $t>0$, let us denote $M_t= \max_{s \leq t} \omega_s$, then $M_t$ and $M_t- \omega_t$ have the same law as $(|\omega_t|)_{t \geq 0}$. 
\end{enumerate}
\end{rem}
\noindent Here is the Reflection principle as presented by Norbert Wiener.
\begin{thm}[Reflection Principle] Let $(W_t)_{t \geq 0}$ be a Wiener process (i.e. a standard Brownian Motion), and let $a>0$ be a treshold (also called a crossing point), then we have 
\begin{align*}
\mathbb{P}_0 \left( \sup_{0 \leq t \leq s } W_t \geq a \right) = 2 \mathbb{P}(  W_s \geq a)
\end{align*} 
\end{thm}
\subsection{Sample path properties of a Brownian Motion}
We start with the important time Inversion Formula for the Brownian Motion.
\begin{prop}[Time Inversion] Let $(B_t)_{t \geq 0}$ be a standard Brownian Motion (i.e. it has law $\mathbb{P}_0$), then $(t B_{1/t})_{t \geq 0}$ is also a standard Brownian Motion (i.e. also has law $\mathbb{P}_0$). 
\end{prop}
\begin{proof}
Let us define the process $Z_t:= t B_{1/t}$. Then clearly $(Z_t)_{t \geq 0}$ is a Gaussian process which is continuous for all $t>0$ (we need to pay seperate attention the time $t=0$). Moreover we have for all $s,t \in \mathbb{R}_0^+$,
\begin{align*}
\mathbb{E}(Z_tZ_s)= ts \mathbb{E}(B_{1/t}B_{1/s}) = ts \min \left( \frac{1}{t}, \frac{1}{s} \right) = \min (t, s ) 
\end{align*}
It remains to show that $\lim_{t \to 0} Z_t=0$, i.e. $Z_t$ is continuous at $t=0$. We notice that by Kolmogorov's LLN we have $\lim_{n \to \infty} \frac{B_n}{n}=0$ almost surely. Showing that $\lim_{t \to 0} Z_t =0$ is equivalent to showing that for all $\epsilon >0$ we have 
\begin{align*}
\mathbb{P}\left( \limsup_{t \to \infty} \frac{|B_t|}{t} > \epsilon \right) =0 
\end{align*}
\newpage
By the Reflection principle we obtain for all $\lambda >0$ that 
\begin{align*}
\mathbb{P}\left( \sup_{n \leq s \leq n+1 }  B_s \geq \lambda \right) = 2 \mathbb{P}( B_1 \geq \lambda) = \mathbb{P}( |B_1| \geq \lambda) \leq 2 e^{- \lambda^2/ 2}
\end{align*}
Specializing this bound on $\lambda= \sqrt{n}$ for a $n \in \mathbb{N}_{\geq 1}$ gives a summable upper bound. Thus by Borel-Cantelli Lemma we obtain that 
\begin{align*}
\sup_{n \leq s \leq n+1} B_s \leq \sqrt{n}, \text{ almost surely, eventually}. 
\end{align*}
This establishes that 
\begin{align*}
\limsup_{s \to \infty} \frac{B_s}{s} = 0, \text{ almost surely}. 
\end{align*}
Just replacing $B_s$ with $-B_s$ gives the statement about the liminf, we conclude that $\lim_{s \to \infty} B_s/s =0. $
\end{proof}
\begin{cor}[0/1 Law] Let $\tau = \displaystyle \bigcap_{t >0} \sigma( \omega_s : s \geq t )$ (tail $\sigma$-algebra), if $A \in \tau$, then $\mathbb{P}_x(A) \in \lbrace 0 , 1 \rbrace$ for all $ x \in \mathbb{R}$. 
\end{cor}
\noindent The next Proposition entails that the behaviour of a Brownian Motion is rather wild around its origin (conveniently picked to be at zero) and oscilating in general for large values of $t$. 
\begin{prop} We have $\mathbb{P}_0$-almost surely that 
\begin{align*}
\limsup_{t \to 0} \frac{\omega_t}{\sqrt{t}} = + \infty \text{ and } \liminf_{t \to 0} \frac{\omega_t}{\sqrt{t}}= - \infty
\end{align*}
It also follows that 
\begin{align*}
\limsup_{t \to \infty}  \frac{\omega_t}{\sqrt{t}}= + \infty \text{ and } \liminf_{t \to \infty} \frac{\omega_t}{\sqrt{t}} = - \infty 
\end{align*}
\end{prop}
\begin{proof}
Let $a >0$ be arbitrary, by symmetry it is enough to establish that 
\begin{align*}
\mathbb{P}_0 \Big( \underbrace{\limsup_{t \to 0} \frac{\omega_t}{\sqrt{t}} > a}_{ \in \mathcal{F}_0^+} \Big) = 1
\end{align*}
By Blumenthal's 0/1 law, we just need to show that the above probability is strictly positive (since it can either be 0 or 1). However, we easily see that 
\begin{align*}
\mathbb{P}_0 \left( \limsup_{ \to 0} \frac{\omega_t}{\sqrt{t}} > a \right) & = \lim_{ \epsilon \to 0} \mathbb{P}_0 \left( \sup_{0 \leq t \leq \epsilon} \frac{\omega_t}{\sqrt{t}} >a \right) \\
& \geq \lim_{ \epsilon \to 0 } \mathbb{P}_0 \left( \frac{\omega_\epsilon}{\sqrt{\epsilon}} > a \right) = \mathbb{P}( \mathcal{N}(0,1) >a)>0 
\end{align*}
\end{proof}
\newpage
\begin{defn} Let $f$ be a real or complex-valued function on $\mathbb{R}$ and let $ 0 < \alpha \leq 1$. We say that $f$ is $\alpha$-Hölder continuous or that it satisfies a Hölder condition when there exists a real constant $C>0$ such that  
\begin{align*}
|f(x)-f(y)| \leq C |x-y|^\alpha, \text{ for all } x ,y \in \mathbb{R}.
\end{align*}
\end{defn}
\begin{rem} \
\begin{enumerate}
\item We say $f$ is (locally) $\alpha$-Hölder continuous at $t \in \mathbb{R}$ if there exists a $\delta >0$ such that for  all $|x-y| < \delta$ the above inequality is satisfied.
\item For $\alpha = 1$ we obtain the Lipschitz-Continuity. The case $\alpha=0$ isn't interesting because it only gives us bounded but not necessarily continuous functions. Moreover it can be shown that for $\alpha >1$ only constant functions satisfy the Hölder condition.
\item We have the following chain of inclusions for all $\alpha \in (0,1]$: \\ Continuously differentiable $\subset$ Lipschitz continuous $\subset$ $\alpha$-Hölder continuous $\subset$ uniformly continuous $\subset$ continuous. 
\end{enumerate}
\end{rem}
\begin{prop} For any $\alpha > 1/2$, $\mathbb{P}_0$ almost surely, the sample paths of $\omega$ are nowhere $\alpha$-Hölder-continuous. In particular, $\mathbb{P}_0$ almost-surely, the function $t \mapsto \omega_t$ is nowhere differentiable. 
\end{prop}
\begin{proof}
Let $C>0$ and $\alpha > 1/2$. For any natural number $N \geq 1$ we define the set 
\begin{align*}
A_N:= \lbrace t \in [0,1] : |\omega_s- \omega_t| \leq C |t-s|^\alpha, \text{ for all $s$}: |s-t| \leq 1/N \rbrace 
\end{align*}
We want to show that $\mathbb{P}_0(A_N)=0$ for all $N \geq 1$. In fact, we have that $A_N$ is an increasing sequence of events, so we only need to prove that  
\begin{align*}
\lim_{N \to \infty} \mathbb{P}_0(A_N)=0 
\end{align*}
Let $n \in \mathbb{N}$ and for all $k = 0, 1 , \dots , 2nN$ define
\begin{align*}
Z_{N,k}:= \max_{j=1, \dots , n} \left| \frac{\omega_{j+k}}{2nN} - \frac{\omega_{j+k-1}}{2nN} \right| 
\end{align*}
Let us now define the set \begin{align*}
D_N:= \left\lbrace k : Z_{N,k} \leq \frac{2C}{N^\alpha} \right\rbrace 
\end{align*}
We claim that that $A_n \subset D_n$, indeed for $ \omega \in A_N$ we set $k = \lfloor 2nNt \rfloor$, then the triangle inequality gives us
\begin{align*}
\left| \frac{\omega_{j+k+1}}{2nN} - \frac{\omega_{j+k}}{2nN} \right| \leq \left| \frac{\omega_{j+k+1}}{2nN}- \omega_t \right| + \left| \omega_t - \frac{\omega_{j+k}}{2nN} \right| \leq \frac{C}{N^\alpha} + \frac{C}{N^\alpha} = \frac{2C}{N^\alpha}
\end{align*}
which shows that $\omega \in D_N$, consequentally we have that $\mathbb{P}_0(A_N) \leq \mathbb{P}_0(D_N)$. 
\newpage
Since for $j=1, \dots , n$ the random variables 
\begin{align*}
\frac{\omega_{j+1+1}}{2nN} - \frac{\omega_{j+k}}{2nN}
\end{align*}
are i.i.d. $\mathcal{N}(0, 1/2nN)$ it follows that $Z_{N,k}$ are identically distributed for all $k=0, 1, \dots , 2nN$. Thus we can easily establish the bound
\begin{align*}
\mathbb{P}_0(D_N) \leq 2nN \mathbb{P}_0 \left( Z_{N,k} \leq \frac{2C}{N^\alpha} \right) = 2nN \mathbb{P}_0 \left( \left| \mathcal{N} \left( 0, \frac{1}{2nN} \right) \right| \leq \frac{2C}{N^\alpha} \right)^n 
\end{align*}
Using the trivial bound $\mathbb{P}(| \mathcal{N}(0,1)| \leq \lambda ) \leq \lambda$ for all $\lambda >0$ we find that
\begin{align*}
\mathbb{P}_0(D_N) &\leq 2nN \mathbb{P} \left(\frac{1}{\sqrt{2nN}} | \mathcal{N}(0,1)| \leq \frac{2C}{N^\alpha} \right)^n \\
& = 2nN \mathbb{P}( | \mathcal{N}(0,1) | \leq C_n N^{1/2- \alpha} ) ^n \leq 2nC_n^n N^{n \left( \frac{1}{2}- \alpha \right)+1} 
\end{align*}
Since $\alpha > \frac{1}{2}$, we have that $(1/2 - \alpha) < 0$, choosing $n \in \mathbb{N}$ large enough we can guarantee that $n(0.5- \alpha) +1 <0 $. We conclude that 
\begin{align*}
\lim_{N \to \infty} \mathbb{P}_0 (D_N)=0, \text{ and thus } \lim_{N \to \infty} \mathbb{P}_0(A_N)=0
\end{align*}
\end{proof}
\begin{rem} For any $0<\alpha < \frac{1}{2}$ one can show, that $\mathbb{P}_0$ almost surely, the sample path of $\omega$ are in fact $\alpha$-Hölder continuous at every point. However, no statement is possible for the case $ \alpha = 1/2$. 
\end{rem}
\begin{prop}[Law of iterated logarithm] Let $h_t:= \sqrt{ 2t \log | \log(t)|}$ for any $t>0$, then $\mathbb{P}_0$ almost surely we have 
\begin{align*}
\limsup_{t \to 0} \frac{\omega_t}{h_t}&=1 \\
\liminf_{t \to 0} \frac{\omega_t}{h_t}& = -1 \\
\limsup_{t \to \infty} \frac{\omega_t}{h_t} & = 1  
\end{align*}
\end{prop}
\begin{proof}
Exercise! 
\end{proof}
\newpage
\subsection{Martingales derived from Brownian Motion}
Let $B$ be a standard Brownian Motion
\begin{prop} Let $(B_t)_{t \geq 0}$ be a standard Brownian Motion, then the following processes are martingales:
\begin{enumerate}
\item $(B_t^2-t)_{t \geq 0}$ 
\item $M_t^\alpha = \exp\left( \alpha B_t - \frac{\alpha^2}{2}t \right)$ for all $t \geq 0$ with expected value $1$. 
\item $\left( \dfrac{d}{d \alpha} \right)^k M_{t \ \mid \alpha =0} ^\alpha$, for any $k \in \mathbb{N}$
\end{enumerate}
\end{prop}
\begin{proof}
Exercise!
\end{proof}
\begin{thm}[Skorokhod's Theorem] Let $\xi$ be a random variable such that $\mathbb{E}( \xi)=0$ and $\mathbb{E}( \xi^2)= \sigma^2$. Then there exists a stopping time $\tau$ such that $\mathbb{E}( \tau)= \sigma^2$ and 
\begin{align*}
B_\tau \overset{d}= \xi. 
\end{align*}
\end{thm}
\noindent In order to prove Skorokhod's Theorem we have another relevant exercise, it is a special case of Skorokho'ds Theorem for centered Bernoulli random variables. 
\begin{prop} For any $\alpha \in \mathbb{R}$, let $\tau_\alpha = \inf \lbrace t >0 : \omega_t = \alpha \rbrace$. \\ If $\alpha < x < \beta$, show that $\mathbb{E}_x( \tau_\alpha \wedge \tau_\beta) < \infty$ and 
\begin{align*}
\mathbb{P}_x ( \tau_\alpha < \tau_\beta) = \frac{\beta-x}{\beta-\alpha}
\end{align*}
Deduce that if $X$ is a centered Bernoulli random variable taking values in $\lbrace a, \beta \rbrace$, then there exists a stopping time $\Lambda$ with finite mean so that $X$ and $\omega_\Lambda$ have the same law under $\mathbb{P}_0$. 
\end{prop}
\begin{proof}
Exercise!
\end{proof}
\begin{rem} The strategy behind the proof of Skorokhod's Theorem is that we construct a sequence $\xi_n$ (taking finitely many values) such that $\xi_n \to \xi$ almost surely. Moreover we construct an increasing sequence of stopping times $\tau_n \uparrow \tau$ such that $\mathbb{E}( \tau ) < \infty$ and 
\begin{align*}
B_{\tau_n} \overset{d}= \xi_n
\end{align*}
The initiatel step is supported the above exercise, we then proceed iteratively by segmentation. 
\end{rem}
\newpage
\noindent Finally we will state Donsker's invariance Theorem. Let $\xi_1, \xi_2, \dots$ be a sequence of i.i.d. Random Variables with mean zero and variance 1. Let $S_0:=0$ and $S_n = \xi_1 + \dots + \xi_n$ for all $n \geq 1$ be a Random Walk. We consider the continuous embedding of this Random Walk on the unit interval $[0,1]$, i.e. let 
\begin{align*}
\widetilde{S_t^N}:= \left\lbrace \frac{S_k+ \left( t- \frac{k}{N}\right) \xi_{k+1}}{\sqrt{N}} : t \in \left[ \frac{k}{N}, \frac{k+1}{N} \right], k = 0,1 \dots , N-1 \right\rbrace 
\end{align*}
\begin{thm}[Donsker's invariance Theorem] $\widetilde{S^N}$ converges in law to a standard Brownian Motion as $N \to \infty$ (in $\mathcal{C})$. This means that for any continuous and bounded function $F: \mathcal{C} \to \mathbb{R}$ we have 
\begin{align*}
\mathbb{E} \left( F \left( \widetilde{S^N} \right) \right) \to \mathbb{E}_0(F), \text{ as } N \to \infty 
\end{align*}
Where $\mathcal{C}=  \lbrace \omega : [0,1] \to \mathbb{R} \mid \text{continuous and } \omega_0 =0 \rbrace$ is a complete (separable) metric space with respect to the $\rho( \omega, \nu) = \sup_{t \in [0,1]} \mid \omega_t - \nu_t |$. 
\end{thm}
\begin{rem} Donsker's Theorem is an invariance theorem because it doesn't depend on the initial law we pick for the i.i.d. sequence $\xi$ that builds our Random Walk. 
\end{rem}
\begin{exmp} $F( \omega):= \sup_{t \in [0,1]} \omega_t$ is a continuous function on $\mathcal{C}$, thus by Donsker's invariance Theorem we obtain that 
\begin{align*}
 \sup_{t \in [0,1]} \widetilde{S_t^N} = \frac{1}{\sqrt{N}} \sup_{k \leq N} (S_k) \implies  \sup_{t \in [0,1]} B_t \overset{d}= | \mathcal{N}(0,1) | 
\end{align*}
\end{exmp}
\begin{exmp} Let $F( \omega) = \omega_1$ be defined on $\mathcal{C}$, then we obtain the classical CLT because 
\begin{align*}
F(\widetilde{S^N})=\widetilde{S_1^N} = \frac{S_N}{\sqrt{N}} 
\end{align*}
and consequently 
\begin{align*}
\frac{S_N}{\sqrt{N}} \implies \mathcal{N}(0,1), \text{ as } N \to \infty. 
\end{align*}
\end{exmp}
\newpage
\section{Summary}
After working through this Script and the relevant exercises the following topics should be understood, \textbf{bold} means in particular important. 
\begin{enumerate}
\item Measures on product spaces
\begin{itemize}
\item \textbf{Kolmogorov's extension theorem}
\item \textbf{Weak convergence (Portmanteau's Theorem)}
\item càdlàg measurability issues (e.g. martingale regularization thm)
\item Gaussian process 
\end{itemize}
\item Martingales
\begin{itemize}
\item \textbf{Basics (definition, conditional expectation etc)}
\item \textbf{Uniform integrability and martingale convergence theorems}
\item \textbf{Basic properties of Random Walks}
\item Galton-Watson processes (extinction/survival)
\end{itemize}
\item Convergence Theorems
\begin{itemize}
\item \textbf{Strong law of large numbers}
\item \textbf{Classical CLT (i.i.d. RVs)}
\item Mc Leish CLT for tarray of martingale differences
\item \textbf{Markov Property (and definition of Markov Process)}
\item Classification of Markov Chains
\item \textbf{Ergodic Theorem (for countable state spaces with proof, renewal times)}
\item Convergence theorem for aperiodic positive recurrent chains (existence and uniqueness of the equilibirum measure)
\end{itemize}
\item Dynamical Systems
\begin{itemize}
\item Poincaré recurrence theorem
\item Von Neumann Ergodic Theorem
\end{itemize}
\item Brownian Motion
\begin{itemize}
\item \textbf{Definitions}
\item Construction (Gaussian Hilbert space etc)
\item Basic properties: \textbf{scaling invariance, markov property, time inversion.} All with \textbf{proof}!
\item \textbf{Strong markov property}
\item \textbf{0/1 laws (Blumenthal/Kolmogorov)}
\item Reflection principle (consequences: $|B_t| \overset{d}= \sup_{s \in [0,t} B_s)$
\item sample path properties: $\alpha$-Hölder continuity, differentiability, law of iterated logarithm with proof!
\item Skorokhod's Theorem 
\item \textbf{Donsker's Theorem}
\end{itemize}
\end{enumerate}
\end{document}
